{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install and import all the Needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (2.9.2)\n",
      "Requirement already satisfied: keras in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: keras-tuner in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: numpy in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (1.23.3)\n",
      "Requirement already satisfied: wget in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (3.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (1.48.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: setuptools in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (65.3.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: packaging in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: requests in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from keras-tuner) (2.28.1)\n",
      "Requirement already satisfied: kt-legacy in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from keras-tuner) (1.0.4)\n",
      "Requirement already satisfied: ipython in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from keras-tuner) (8.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from requests->keras-tuner) (2022.6.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from requests->keras-tuner) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from requests->keras-tuner) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from requests->keras-tuner) (1.26.12)\n",
      "Requirement already satisfied: traitlets>=5 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from ipython->keras-tuner) (5.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from ipython->keras-tuner) (0.18.1)\n",
      "Requirement already satisfied: stack-data in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from ipython->keras-tuner) (0.5.0)\n",
      "Requirement already satisfied: colorama in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from ipython->keras-tuner) (0.4.5)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from ipython->keras-tuner) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from ipython->keras-tuner) (0.7.5)\n",
      "Requirement already satisfied: decorator in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from ipython->keras-tuner) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from ipython->keras-tuner) (3.0.31)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from ipython->keras-tuner) (2.13.0)\n",
      "Requirement already satisfied: backcall in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from ipython->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from jedi>=0.16->ipython->keras-tuner) (0.8.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: wcwidth in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython->keras-tuner) (0.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pure-eval in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from stack-data->ipython->keras-tuner) (0.2.2)\n",
      "Requirement already satisfied: asttokens in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from stack-data->ipython->keras-tuner) (2.0.8)\n",
      "Requirement already satisfied: executing in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from stack-data->ipython->keras-tuner) (1.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\programs\\anaconda3\\envs\\ai6g\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow keras keras-tuner numpy wget\n",
    "import wget\n",
    "import h5py\n",
    "import keras_tuner \n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Reshape,\n",
    "    Conv2D,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First choose the dataset that will be used on the next steps\n",
    "\n",
    "Datasets available:\n",
    "1. 64x16 Single Pilot 80_Ntrain -5_SNR: \n",
    "2. 8x4 Single Pilot 80_Ntrain -5_SNR: \n",
    "3. 8x4 Single Pilot 80_Ntrain 0_SNR: \n",
    "\n",
    "To download using the notebook change CHOSEN_DATASET on the next script to the desired dataset number(Example: \"CHOSEN_DATASET = 1\" to get the 64x16 Single Pilot 80_Ntrain -5_SNR dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 401: Unauthorized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 11\u001b[0m\n\u001b[0;32m      3\u001b[0m LINKS\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;241m1\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPilots_SNR_(-5dB)_64x16(80pilots)_single_sub.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;241m2\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPilots_SNR_(-5dB)_8x4(80pilots)_single_sub.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_8x4_single_sub\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChannels_8x4_single_sub.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m }\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(LINKS[CHOSEN_DATASET]):\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mwget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_LINK\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLINKS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCHOSEN_DATASET\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m CHOSEN_DATASET \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(LINKS[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChannels_8x4_single_sub\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n",
      "File \u001b[1;32md:\\Programs\\Anaconda3\\envs\\ai6g\\lib\\site-packages\\wget.py:526\u001b[0m, in \u001b[0;36mdownload\u001b[1;34m(url, out, bar)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    525\u001b[0m     binurl \u001b[38;5;241m=\u001b[39m url\n\u001b[1;32m--> 526\u001b[0m (tmpfile, headers) \u001b[38;5;241m=\u001b[39m \u001b[43mulib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinurl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmpfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m filename \u001b[38;5;241m=\u001b[39m detect_filename(url, out, headers)\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outdir:\n",
      "File \u001b[1;32md:\\Programs\\Anaconda3\\envs\\ai6g\\lib\\urllib\\request.py:239\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    240\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Programs\\Anaconda3\\envs\\ai6g\\lib\\urllib\\request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programs\\Anaconda3\\envs\\ai6g\\lib\\urllib\\request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\Programs\\Anaconda3\\envs\\ai6g\\lib\\urllib\\request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\Programs\\Anaconda3\\envs\\ai6g\\lib\\urllib\\request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    560\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programs\\Anaconda3\\envs\\ai6g\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\Programs\\Anaconda3\\envs\\ai6g\\lib\\urllib\\request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 401: Unauthorized"
     ]
    }
   ],
   "source": [
    "CHOSEN_DATASET = 2\n",
    "BASE_LINK=\"https://nextcloud.lasseufpa.org/remote.php/webdav/Lasse/Projects/UFA27_SmartHaul/MIMO-Hybrid-Channel-Estimation/Datasets/\"\n",
    "LINKS={\n",
    "    1:\"Pilots_SNR_(-5dB)_64x16(80pilots)_single_sub.hdf5\",\n",
    "    2:\"Pilots_SNR_(-5dB)_8x4(80pilots)_single_sub.hdf5\",\n",
    "    3:\"Pilots_SNR_(0dB)_8x4(80pilots)_single_sub.hdf5\",\n",
    "    \"channels_64x16_single_sub\":\"Channels_64x16_single_sub.hdf5\",\n",
    "    \"channels_8x4_single_sub\":\"Channels_8x4_single_sub.hdf5\",\n",
    "}\n",
    "if not os.path.isfile(LINKS[CHOSEN_DATASET]):\n",
    "    wget.download(BASE_LINK + LINKS[CHOSEN_DATASET])\n",
    "if CHOSEN_DATASET > 1:\n",
    "    if not os.path.isfile(LINKS[\"Channels_8x4_single_sub\"]):\n",
    "        wget.download(BASE_LINK + LINKS[\"Channels_8x4_single_sub\"])\n",
    "        CHOSEN_CHANNELS = \"Channels_64x16_single_sub.hdf5\"\n",
    "elif not os.path.isfile(LINKS[\"channels_64x16_single_sub\"]):\n",
    "    wget.download(BASE_LINK + LINKS[\"Channels_64x16_single_sub\"])\n",
    "    CHOSEN_CHANNELS = \"Channels_8x4_single_sub.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the following values according to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Keras tuner parameters\n",
    "MAX_TRIALS = 200\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1000\n",
    "\n",
    "\n",
    "# Change these values acording to the dataset\n",
    "NR = 8 \n",
    "NT = 4 \n",
    "LR = 4 \n",
    "CHANNELS_USED = 9000\n",
    "SUBCARIERS_USED_TRAIN = 1\n",
    "SUBCARIERS_USED_OUT = 1\n",
    "NC = 10000\n",
    "NTRAIN = 80\n",
    "CHANNELS_USED_TEST = NC - CHANNELS_USED\n",
    "\n",
    "\n",
    "\n",
    "# Directory of the Channels Matrix file\n",
    "CHANNELS_FILE = h5py.File(LINKS[CHOSEN_DATASET], \"r\")\n",
    "\n",
    "\n",
    "# Directory of the Pilots Matrix file\n",
    "PILOTS_FILE = h5py.File(CHOSEN_CHANNELS, \"r\")\n",
    "\n",
    "\n",
    "input_shape = (NTRAIN * LR, SUBCARIERS_USED_TRAIN)\n",
    "output_shape = (NR, NT, SUBCARIERS_USED_OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will be used as a metric in keras to calculate the NMSE(Normalized Mean Squared Error) for each train or validation example that will be iterated in the training process, providing clear metrics to the whole process and enabling the use of early_stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring the function to calculate NMSE for each batch\n",
    "def NMSEtrainComplex(y_true, y_pred):\n",
    "    sub = y_pred[:, :, :] - y_true[:, :, :]\n",
    "    H_k = y_true[:, :, :]\n",
    "    nmse = tf.norm(sub, ord=\"fro\", axis=(1, 2)) ** 2\n",
    "    den = tf.norm(H_k, ord=\"fro\", axis=(1, 2)) ** 2\n",
    "\n",
    "    result = (nmse / den)\n",
    "\n",
    "    return 10*tf.experimental.numpy.log10(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the NN model will be crated, a chain of Dense layers is being used with relu activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense((512), activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense((512), activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense((512), activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense((512), activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense((512), activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(np.prod(output_shape), activation=\"linear\"))\n",
    "model.add(Reshape(output_shape))\n",
    "model.compile(\n",
    "    loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[NMSEtrainComplex]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_inputData = PILOTS_FILE[\"pilots\"][:NC, :, :SUBCARIERS_USED_TRAIN]\n",
    "training_outputData = CHANNELS_FILE[\"channels\"][:NC, :, :, :SUBCARIERS_USED_OUT]\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "        training_inputData,\n",
    "        training_outputData,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor=\"val_NMSEtrainComplex\",\n",
    "                min_delta=5e-3,\n",
    "                patience=40,\n",
    "                restore_best_weights=True,\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                filepath=\"./model\",\n",
    "                monitor=\"val_NMSEtrainComplex\",\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                7factor=0.5,\n",
    "                min_delta=5e-2,\n",
    "                patience=20,\n",
    "                cooldown=5,\n",
    "                verbose=1,\n",
    "                min_lr=1e-7,\n",
    "            ),\n",
    "        ],\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai6genv)",
   "language": "python",
   "name": "ai6g"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "93c6faf7a6b2e5e76de197b2e43c7ba4b62616900eb00f6bb925ee744c17b34a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
