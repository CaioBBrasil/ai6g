{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install and import all the Needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.10.0 keras-tuner==1.1.3 numpy==1.23.2 h5py==3.7.0\n",
    "import h5py \n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Reshape,\n",
    "    Conv2D,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FILES={\n",
    "    1:\"Pilots_SNR_(-5dB)_64x16(80pilots)_single_sub.hdf5\",\n",
    "    2:\"Pilots_SNR_(-5dB)_8x4(80pilots)_single_sub.hdf5\",\n",
    "    3:\"Pilots_SNR_(0dB)_8x4(80pilots)_single_sub.hdf5\",\n",
    "    \"64x16\":\"Channels_64x16_single_sub.hdf5\",\n",
    "    \"8x4\":\"Channels_8x4_single_sub.hdf5\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the following values according to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_DATASET = 2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1000\n",
    "\n",
    "\n",
    "# Change these values acording to the dataset\n",
    "NR = 8 \n",
    "NT = 4 \n",
    "LR = 4 \n",
    "CHANNELS_USED_TRAIN = 9000\n",
    "SUBCARIERS_USED = 1\n",
    "TOTAL_CHANNELS = 10000\n",
    "NUM_SYM_PILOTS = 80\n",
    "CHANNELS_USED_TEST = TOTAL_CHANNELS - CHANNELS_USED_TRAIN\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (NUM_SYM_PILOTS * LR, SUBCARIERS_USED)\n",
    "output_shape = (NR, NT, SUBCARIERS_USED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECTING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHOSEN_DATASET == 1:\n",
    "    CHOSEN_CHANNELS = FILES[\"64x16\"]\n",
    "elif CHOSEN_DATASET > 1 and CHOSEN_DATASET <=3:\n",
    "    CHOSEN_CHANNELS = FILES[\"8x4\"]\n",
    "\n",
    "\n",
    "# Directory of the Channels Matrix file\n",
    "CHANNELS_FILE = h5py.File(LINKS[CHOSEN_DATASET], \"r\")\n",
    "\n",
    "\n",
    "# Directory of the Pilots Matrix file\n",
    "PILOTS_FILE = h5py.File(CHOSEN_CHANNELS, \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will be used as a metric in keras to calculate the NMSE(Normalized Mean Squared Error) for each train or validation example that will be iterated in the training process, providing clear metrics to the whole process and enabling the use of early_stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring the function to calculate NMSE for each batch\n",
    "def NMSEtrainComplex(y_true, y_pred):\n",
    "    sub = y_pred[:, :, :] - y_true[:, :, :]\n",
    "    H_k = y_true[:, :, :]\n",
    "    nmse = tf.norm(sub, ord=\"fro\", axis=(1, 2)) ** 2\n",
    "    den = tf.norm(H_k, ord=\"fro\", axis=(1, 2)) ** 2\n",
    "\n",
    "    result = (nmse / den)\n",
    "\n",
    "    return 10*tf.experimental.numpy.log10(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the NN model will be crated, a chain of Dense layers is being used with relu activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense((512), activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense((512), activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense((512), activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense((512), activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense((512), activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(np.prod(output_shape), activation=\"linear\"))\n",
    "model.add(Reshape(output_shape))\n",
    "model.compile(\n",
    "    loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[NMSEtrainComplex]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_inputData = PILOTS_FILE[\"pilots\"][:CHANNELS_USED_TRAIN, :, :SUBCARIERS_USED]\n",
    "training_outputData = CHANNELS_FILE[\"channels\"][:CHANNELS_USED_TRAIN, :, :, :SUBCARIERS_USED]\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "        training_inputData,\n",
    "        training_outputData,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor=\"val_NMSEtrainComplex\",\n",
    "                min_delta=5e-3,\n",
    "                patience=40,\n",
    "                restore_best_weights=True,\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                filepath=\"./model\",\n",
    "                monitor=\"val_NMSEtrainComplex\",\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                factor=0.5,\n",
    "                min_delta=5e-2,\n",
    "                patience=20,\n",
    "                cooldown=5,\n",
    "                verbose=1,\n",
    "                min_lr=1e-7,\n",
    "            ),\n",
    "        ],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_INPUT = PILOTS_FILE[\"pilots\"][CHANNELS_USED_TRAIN:, :, :SUBCARIERS_USED]\n",
    "TEST_OUTPUT = CHANNELS_FILE[\"channels\"][CHANNELS_USED_TRAIN:, :, :, :SUBCARIERS_USED]\n",
    "\n",
    "result = model.predict(TEST_INPUT)\n",
    "\n",
    "\n",
    "print(np.average(np.real(NMSEtrainComplex(TEST_OUTPUT, result))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93c6faf7a6b2e5e76de197b2e43c7ba4b62616900eb00f6bb925ee744c17b34a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
