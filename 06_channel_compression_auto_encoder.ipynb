{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90331bNe5Ucu"
   },
   "source": [
    "# Overview\n",
    "\n",
    "This notebook is organized as follows:\n",
    "- Section 01 contains the cells responsible for testing the CNN model for CSI compression.\n",
    "- Section 02 contains the cells responsible for training the CNN model for CSI compression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGFXradn5DBd"
   },
   "source": [
    "# Section 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U7_lLzaJ66Cb"
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense, BatchNormalization, Reshape, Conv2D, add, LeakyReLU\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.callbacks import TensorBoard, Callback\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E-LT3IJBCRD8"
   },
   "outputs": [],
   "source": [
    "# Set image and network params\n",
    "envir = 'indoor' #choose between 'indoor' or 'outdoor'\n",
    "\n",
    "# Image params\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "img_channels = 2 \n",
    "img_total = img_height*img_width*img_channels\n",
    "\n",
    "# Network params\n",
    "residual_num = 1 #original value = 2\n",
    "#compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, \n",
    "#compress rate=1/32->dim.=64, compress rate=1/64->dim.=32\n",
    "encoded_dim = 32 #original value = 512\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JjCGizqwCyfi"
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model and weights\n",
    "file = 'CsiNet_'+(envir)+'_dim'+str(encoded_dim)\n",
    "\n",
    "# Load json and create model\n",
    "outfile = \"./files_06_channel/saved_model/model_%s.json\"%file\n",
    "json_file = open(outfile, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "autoencoder = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load weights from a pre-trained model\n",
    "outfile = \"./files_06_channel/saved_model/model_%s.h5\"%file\n",
    "autoencoder.load_weights(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O2miKM-aDYef"
   },
   "outputs": [],
   "source": [
    "# Load dataset for testing\n",
    "if envir == 'indoor':\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_Htestin.mat')\n",
    "  x_test = mat['HT'] # array\n",
    "\n",
    "elif envir == 'outdoor':\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_Htestout.mat')\n",
    "  x_test = mat['HT'] # array\n",
    "\n",
    "x_test = x_test.astype('float32')\n",
    "x_test = np.reshape(x_test, (len(x_test), img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eZyFWM4AD3EM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 5s 3ms/step\n",
      "It took an average of 0.000316 seconds per example to evaluate the model on the test set\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "tStart = time.time()\n",
    "x_hat = autoencoder.predict(x_test)\n",
    "tEnd = time.time()\n",
    "print (\"It took an average of %f seconds per example to evaluate the model on the test set\" % ((tEnd - tStart)/x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5c7A8smD_WI"
   },
   "outputs": [],
   "source": [
    "# Calculating the NMSE and rho (correlation)\n",
    "\n",
    "# Load data with 125 (subcarriers) * 32 (antenna) to calculate rho\n",
    "if envir == 'indoor':\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_HtestFin_all.mat')\n",
    "  X_test = mat['HF_all']# array\n",
    "\n",
    "elif envir == 'outdoor':\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_HtestFout_all.mat')\n",
    "  X_test = mat['HF_all']# array\n",
    "\n",
    "X_test = np.reshape(X_test, (len(X_test), img_height, 125))\n",
    "x_test_real = np.reshape(x_test[:, 0, :, :], (len(x_test), -1))\n",
    "x_test_imag = np.reshape(x_test[:, 1, :, :], (len(x_test), -1))\n",
    "x_test_C = x_test_real-0.5 + 1j*(x_test_imag-0.5)\n",
    "x_hat_real = np.reshape(x_hat[:, 0, :, :], (len(x_hat), -1))\n",
    "x_hat_imag = np.reshape(x_hat[:, 1, :, :], (len(x_hat), -1))\n",
    "x_hat_C = x_hat_real-0.5 + 1j*(x_hat_imag-0.5)\n",
    "x_hat_F = np.reshape(x_hat_C, (len(x_hat_C), img_height, img_width))\n",
    "X_hat = np.fft.fft(np.concatenate((x_hat_F, np.zeros((len(x_hat_C), img_height, 257-img_width))), axis=2), axis=2)\n",
    "X_hat = X_hat[:, :, 0:125]\n",
    "\n",
    "n1 = np.sqrt(np.sum(np.conj(X_test)*X_test, axis=1))\n",
    "n1 = n1.astype('float64')\n",
    "n2 = np.sqrt(np.sum(np.conj(X_hat)*X_hat, axis=1))\n",
    "n2 = n2.astype('float64')\n",
    "aa = abs(np.sum(np.conj(X_test)*X_hat, axis=1))\n",
    "rho = np.mean(aa/(n1*n2), axis=1)\n",
    "X_hat = np.reshape(X_hat, (len(X_hat), -1))\n",
    "X_test = np.reshape(X_test, (len(X_test), -1))\n",
    "power = np.sum(abs(x_test_C)**2, axis=1)\n",
    "power_d = np.sum(abs(X_hat)**2, axis=1)\n",
    "mse = np.sum(abs(x_test_C-x_hat_C)**2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mPNDSQsEbOr"
   },
   "outputs": [],
   "source": [
    "print(\"In \"+envir+\" environment\")\n",
    "print(\"When dimension is\", encoded_dim)\n",
    "print(\"NMSE is \", 10*math.log10(np.mean(mse/power)))\n",
    "print(\"Correlation is \", np.mean(rho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMGFSiVZEqL2"
   },
   "outputs": [],
   "source": [
    "# Display the original and reconstructed pseudo-gray plots of the strength of H\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "  # display original\n",
    "  ax = plt.subplot(2, n, i + 1 )\n",
    "  x_testplo = abs(x_test[i, 0, :, :]-0.5 + 1j*(x_test[i, 1, :, :]-0.5))\n",
    "  plt.imshow(np.max(np.max(x_testplo))-x_testplo.T)\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "  ax.invert_yaxis()\n",
    "  \n",
    "  # display reconstructed\n",
    "  ax = plt.subplot(2, n, i + 1 + n)\n",
    "  decoded_imgsplo = abs(x_hat[i, 0, :, :]-0.5\n",
    "                        + 1j*(x_hat[i, 1, :, :]-0.5))\n",
    "  plt.imshow(np.max(np.max(decoded_imgsplo))-decoded_imgsplo.T)\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "  ax.invert_yaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtRCCt3l6pOV"
   },
   "source": [
    "# Section 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2erDuVef6_KO"
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense, BatchNormalization, Reshape, Conv2D, add, LeakyReLU\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.callbacks import TensorBoard, Callback\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqXCkcfo7OPL"
   },
   "outputs": [],
   "source": [
    "# Set image and network params\n",
    "envir = 'indoor' #'indoor' or 'outdoor'\n",
    "\n",
    "# Image params\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "img_channels = 2 \n",
    "img_total = img_height*img_width*img_channels\n",
    "\n",
    "# Network params\n",
    "residual_num = 2\n",
    "encoded_dim = 512  #compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, compress rate=1/32->dim.=64, compress rate=1/64->dim.=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mnOkmZjU7RI6"
   },
   "outputs": [],
   "source": [
    "# Build the autoencoder model (CNN model) of CsiNet\n",
    "def residual_network(x, residual_num, encoded_dim):\n",
    "  def add_common_layers(y):\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    \n",
    "    return y\n",
    "  \n",
    "  def residual_block_decoded(y):\n",
    "    shortcut = y\n",
    "    y = Conv2D(8, kernel_size=(3, 3), padding='same', data_format='channels_first')(y)\n",
    "    y = add_common_layers(y)\n",
    "    \n",
    "    y = Conv2D(16, kernel_size=(3, 3), padding='same', data_format='channels_first')(y)\n",
    "    y = add_common_layers(y)\n",
    "    \n",
    "    y = Conv2D(2, kernel_size=(3, 3), padding='same', data_format='channels_first')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    y = add([shortcut, y])\n",
    "    y = LeakyReLU()(y)\n",
    "\n",
    "    return y\n",
    "  \n",
    "  x = Conv2D(2, (3, 3), padding='same', data_format=\"channels_first\")(x)\n",
    "  x = add_common_layers(x)\n",
    "  \n",
    "  x = Reshape((img_total,))(x)\n",
    "  encoded = Dense(encoded_dim, activation='linear')(x)\n",
    "  \n",
    "  x = Dense(img_total, activation='linear')(encoded)\n",
    "  x = Reshape((img_channels, img_height, img_width,))(x)\n",
    "  for i in range(residual_num):\n",
    "    x = residual_block_decoded(x)\n",
    "  \n",
    "  x = Conv2D(2, (3, 3), activation='sigmoid', padding='same', data_format=\"channels_first\")(x)\n",
    "  \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H8DnkqPe8IXw"
   },
   "outputs": [],
   "source": [
    "# Set autoencoder model params and display the network model\n",
    "image_tensor = Input(shape=(img_channels, img_height, img_width))\n",
    "network_output = residual_network(image_tensor, residual_num, encoded_dim)\n",
    "autoencoder = Model(inputs=[image_tensor], outputs=[network_output])\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meKKoN-f8Z80"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "if envir == 'indoor':\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_Htrainin.mat') \n",
    "  x_train = mat['HT'] # array\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_Hvalin.mat')\n",
    "  x_val = mat['HT'] # array\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_Htestin.mat')\n",
    "  x_test = mat['HT'] # array\n",
    "\n",
    "elif envir == 'outdoor':\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_Htrainout.mat') \n",
    "  x_train = mat['HT'] # array\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_Hvalout.mat')\n",
    "  x_val = mat['HT'] # array\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_Htestout.mat')\n",
    "  x_test = mat['HT'] # array\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = np.reshape(x_train, (len(x_train), img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\n",
    "x_val = np.reshape(x_val, (len(x_val), img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qm9CimNI9h4c"
   },
   "outputs": [],
   "source": [
    "# Create a class to save the loss history of the model\n",
    "class LossHistory(Callback):\n",
    "  def on_train_begin(self, logs={}):\n",
    "    self.losses_train = []\n",
    "    self.losses_val = []\n",
    "  \n",
    "  def on_batch_end(self, batch, logs={}):\n",
    "    self.losses_train.append(logs.get('loss'))    \n",
    "    \n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    self.losses_val.append(logs.get('val_loss'))\n",
    "\n",
    "history = LossHistory()\n",
    "file = 'CsiNet_'+(envir)+'_dim'+str(encoded_dim)+time.strftime('_%m_%d')\n",
    "path = 'files_06_channel/result/TensorBoard_%s' %file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PVFELTj_9uKl"
   },
   "outputs": [],
   "source": [
    "# Train the model with the specified params and save the train loss and val loss in a csv file\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=10, #original value = 1000\n",
    "                batch_size=20, #original value = 200\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val, x_val),\n",
    "                callbacks=[history,\n",
    "                           TensorBoard(log_dir = path)])\n",
    "\n",
    "filename = 'files_06_channel/result/trainloss_%s.csv'%file\n",
    "loss_history = np.array(history.losses_train)\n",
    "np.savetxt(filename, loss_history, delimiter=\",\")\n",
    "\n",
    "filename = 'files_06_channel/result/valloss_%s.csv'%file\n",
    "loss_history = np.array(history.losses_val)\n",
    "np.savetxt(filename, loss_history, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jnfm6hJ-zpt"
   },
   "outputs": [],
   "source": [
    "# Testing data\n",
    "tStart = time.time()\n",
    "x_hat = autoencoder.predict(x_test)\n",
    "tEnd = time.time()\n",
    "print (\"It cost %f sec\" % ((tEnd - tStart)/x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJcp8f_5--Zp"
   },
   "outputs": [],
   "source": [
    "# Calculating the NMSE and rho\n",
    "if envir == 'indoor':\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_HtestFin_all.mat')\n",
    "  X_test = mat['HF_all']# array\n",
    "\n",
    "elif envir == 'outdoor':\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_HtestFout_all.mat')\n",
    "  X_test = mat['HF_all']# array\n",
    "\n",
    "X_test = np.reshape(X_test, (len(X_test), img_height, 125))\n",
    "x_test_real = np.reshape(x_test[:, 0, :, :], (len(x_test), -1))\n",
    "x_test_imag = np.reshape(x_test[:, 1, :, :], (len(x_test), -1))\n",
    "x_test_C = x_test_real-0.5 + 1j*(x_test_imag-0.5)\n",
    "x_hat_real = np.reshape(x_hat[:, 0, :, :], (len(x_hat), -1))\n",
    "x_hat_imag = np.reshape(x_hat[:, 1, :, :], (len(x_hat), -1))\n",
    "x_hat_C = x_hat_real-0.5 + 1j*(x_hat_imag-0.5)\n",
    "x_hat_F = np.reshape(x_hat_C, (len(x_hat_C), img_height, img_width))\n",
    "X_hat = np.fft.fft(np.concatenate((x_hat_F, np.zeros((len(x_hat_C), img_height, 257-img_width))), axis=2), axis=2)\n",
    "X_hat = X_hat[:, :, 0:125]\n",
    "\n",
    "n1 = np.sqrt(np.sum(np.conj(X_test)*X_test, axis=1))\n",
    "n1 = n1.astype('float64')\n",
    "n2 = np.sqrt(np.sum(np.conj(X_hat)*X_hat, axis=1))\n",
    "n2 = n2.astype('float64')\n",
    "aa = abs(np.sum(np.conj(X_test)*X_hat, axis=1))\n",
    "rho = np.mean(aa/(n1*n2), axis=1)\n",
    "X_hat = np.reshape(X_hat, (len(X_hat), -1))\n",
    "X_test = np.reshape(X_test, (len(X_test), -1))\n",
    "power = np.sum(abs(x_test_C)**2, axis=1)\n",
    "power_d = np.sum(abs(X_hat)**2, axis=1)\n",
    "mse = np.sum(abs(x_test_C-x_hat_C)**2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8k1F4iE_Pdw"
   },
   "outputs": [],
   "source": [
    "print(\"In \"+envir+\" environment\")\n",
    "print(\"When dimension is\", encoded_dim)\n",
    "print(\"NMSE is \", 10*math.log10(np.mean(mse/power)))\n",
    "print(\"Correlation is \", np.mean(rho))\n",
    "\n",
    "filename = \"files_06_channel/result/decoded_%s.csv\"%file\n",
    "x_hat1 = np.reshape(x_hat, (len(x_hat), -1))\n",
    "np.savetxt(filename, x_hat1, delimiter=\",\")\n",
    "filename = \"files_06_channel/result/rho_%s.csv\"%file\n",
    "np.savetxt(filename, rho, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2p7tvVn7_WeS"
   },
   "outputs": [],
   "source": [
    "# Display the original and reconstructed pseudo-gray plots of the strength of H\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "  # display original\n",
    "  ax = plt.subplot(2, n, i + 1 )\n",
    "  x_testplo = abs(x_test[i, 0, :, :]-0.5 + 1j*(x_test[i, 1, :, :]-0.5))\n",
    "  plt.imshow(np.max(np.max(x_testplo))-x_testplo.T)\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "  ax.invert_yaxis()\n",
    "  \n",
    "  # display reconstructed\n",
    "  ax = plt.subplot(2, n, i + 1 + n)\n",
    "  decoded_imgsplo = abs(x_hat[i, 0, :, :]-0.5\n",
    "                        + 1j*(x_hat[i, 1, :, :]-0.5))\n",
    "  plt.imshow(np.max(np.max(decoded_imgsplo))-decoded_imgsplo.T)\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "  ax.invert_yaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmfCljB0_9oE"
   },
   "outputs": [],
   "source": [
    "# Save the model and the weights of the autoencoder\n",
    "model_json = autoencoder.to_json()\n",
    "outfile = \"files_06_channel/result/my_model_%s.json\"%file\n",
    "with open(outfile, \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "outfile = \"files_06_channel/result/my_model_%s.h5\"%file\n",
    "autoencoder.save_weights(outfile)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (ai6genv)",
   "language": "python",
   "name": "ai6g"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
