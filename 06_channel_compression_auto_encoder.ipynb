{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts\n",
    "### Channel State Information\n",
    "\n",
    "CSI represents how wireless signals propagate from the transmitter to the receiver at certain carrier frequencies along multiple paths. For a WiFi system with MIMO-OFDM, CSI is a threedimensional (3D) matrix of complex values representing the amplitude attenuation and phase shift of multi-path WiFi channels. A time series of CSI measurements captures how wireless signals travel through surrounding objects and humans in time, frequency, and spatial domains, so it can be used for different wireless sensing applications. For example, CSI amplitude variations in the time domain have different patterns for different humans, activities, gestures, and so on, which can be used for human presence detection,  fall detection, motion detection, activity recognition, gesture recognition, and human identification/authentication. CSI phase shifts in the spatial and frequency domains, i.e., transmit/receive antennas and carrier frequencies, are related to signal transmission delay and direction, which can be used for human localization and tracking. CSI phase shifts in the time domain may have different dominant frequency components that can be used to estimate breathing rate [1].\n",
    "\n",
    "\n",
    "### Auto-encoder\n",
    "\n",
    "Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible. Autoencoder, by design, reduces data dimensions by learning how to ignore the noise in the data [2].\n",
    "\n",
    "### CSI compression\n",
    "\n",
    "CSI compression is used to compress and encode the CSI for downlink MIMO channels. This method can be used to reduce the network data traffic with minimal loss of performance. \n",
    "\n",
    "### References\n",
    "\n",
    "[1] Yongsen Ma, Gang Zhou, and Shuangquan Wang. 2019. WiFi Sensing with Channel State Information: A Survey. ACM Comput. Surv. 52, 3, Article 46 (May 2020), 36 pages. https://doi.org/10.1145/3310194\n",
    "\n",
    "[2] Badr, W. (2021, December 9). Auto-Encoder: What Is It? And What Is It Used For? (Part 1). Medium. Retrieved September 6, 2022, from https://towardsdatascience.com/auto-encoder-what-is-it-and-what-is-it-used-for-part-1-3e5c6f017726"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7_lLzaJ66Cb"
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense, BatchNormalization, Reshape, Conv2D, add, LeakyReLU\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.callbacks import TensorBoard, Callback\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-LT3IJBCRD8"
   },
   "outputs": [],
   "source": [
    "# Set image and network params\n",
    "envir = 'indoor' #'indoor' or 'outdoor'\n",
    "\n",
    "# Image params\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "img_channels = 2 \n",
    "img_total = img_height*img_width*img_channels\n",
    "\n",
    "# Network params\n",
    "residual_num = 2\n",
    "encoded_dim = 512  #compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, compress rate=1/32->dim.=64, compress rate=1/64->dim.=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JjCGizqwCyfi"
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model and weights\n",
    "file = 'CsiNet_'+(envir)+'_dim'+str(encoded_dim)\n",
    "\n",
    "# Load json and create model\n",
    "outfile = \"./files_06_channel/saved_model/model_%s.json\"%file\n",
    "json_file = open(outfile, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "autoencoder = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load weights outto new model\n",
    "outfile = \"./files_06_channel/saved_model/model_%s.h5\"%file\n",
    "autoencoder.load_weights(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2miKM-aDYef"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "if envir == 'indoor':\n",
    "    mat = sio.loadmat('./files_06_channel/data/DATA_Htestin.mat')\n",
    "    x_test = mat['HT'] # array\n",
    "\n",
    "elif envir == 'outdoor':\n",
    "    mat = sio.loadmat('./files_06_channel/data/DATA_Htestout.mat')\n",
    "    x_test = mat['HT'] # array\n",
    "\n",
    "x_test = x_test.astype('float32')\n",
    "x_test = np.reshape(x_test, (len(x_test), img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZyFWM4AD3EM"
   },
   "outputs": [],
   "source": [
    "# Testing data\n",
    "tStart = time.time()\n",
    "x_hat = autoencoder.predict(x_test)\n",
    "tEnd = time.time()\n",
    "print (\"It cost %f sec\" % ((tEnd - tStart)/x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5c7A8smD_WI"
   },
   "outputs": [],
   "source": [
    "# Calcaulating the NMSE and rho\n",
    "\n",
    "# Load data with 125 (subcarriers) * 32 (antenna) to calculate rho\n",
    "if envir == 'indoor':\n",
    "    mat = sio.loadmat('./files_06_channel/data/DATA_HtestFin_all.mat')\n",
    "    X_test = mat['HF_all']# array\n",
    "\n",
    "elif envir == 'outdoor':\n",
    "    mat = sio.loadmat('./files_06_channel/data/DATA_HtestFout_all.mat')\n",
    "    X_test = mat['HF_all']# array\n",
    "\n",
    "X_test = np.reshape(X_test, (len(X_test), img_height, 125))\n",
    "x_test_real = np.reshape(x_test[:, 0, :, :], (len(x_test), -1))\n",
    "x_test_imag = np.reshape(x_test[:, 1, :, :], (len(x_test), -1))\n",
    "x_test_C = x_test_real-0.5 + 1j*(x_test_imag-0.5)\n",
    "x_hat_real = np.reshape(x_hat[:, 0, :, :], (len(x_hat), -1))\n",
    "x_hat_imag = np.reshape(x_hat[:, 1, :, :], (len(x_hat), -1))\n",
    "x_hat_C = x_hat_real-0.5 + 1j*(x_hat_imag-0.5)\n",
    "x_hat_F = np.reshape(x_hat_C, (len(x_hat_C), img_height, img_width))\n",
    "X_hat = np.fft.fft(np.concatenate((x_hat_F, np.zeros((len(x_hat_C), img_height, 257-img_width))), axis=2), axis=2)\n",
    "X_hat = X_hat[:, :, 0:125]\n",
    "\n",
    "n1 = np.sqrt(np.sum(np.conj(X_test)*X_test, axis=1))\n",
    "n1 = n1.astype('float64')\n",
    "n2 = np.sqrt(np.sum(np.conj(X_hat)*X_hat, axis=1))\n",
    "n2 = n2.astype('float64')\n",
    "aa = abs(np.sum(np.conj(X_test)*X_hat, axis=1))\n",
    "rho = np.mean(aa/(n1*n2), axis=1)\n",
    "X_hat = np.reshape(X_hat, (len(X_hat), -1))\n",
    "X_test = np.reshape(X_test, (len(X_test), -1))\n",
    "power = np.sum(abs(x_test_C)**2, axis=1)\n",
    "power_d = np.sum(abs(X_hat)**2, axis=1)\n",
    "mse = np.sum(abs(x_test_C-x_hat_C)**2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mPNDSQsEbOr"
   },
   "outputs": [],
   "source": [
    "print(\"In \"+envir+\" environment\")\n",
    "print(\"When dimension is\", encoded_dim)\n",
    "print(\"NMSE is \", 10*math.log10(np.mean(mse/power)))\n",
    "print(\"Correlation is \", np.mean(rho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMGFSiVZEqL2"
   },
   "outputs": [],
   "source": [
    "# Display the original and reconstructed pseudo-gray plots of the strength of H\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display origoutal\n",
    "    ax = plt.subplot(2, n, i + 1 )\n",
    "    x_testplo = abs(x_test[i, 0, :, :]-0.5 + 1j*(x_test[i, 1, :, :]-0.5))\n",
    "    plt.imshow(np.max(np.max(x_testplo))-x_testplo.T)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.invert_yaxis()\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    decoded_imgsplo = abs(x_hat[i, 0, :, :]-0.5 \n",
    "                          + 1j*(x_hat[i, 1, :, :]-0.5))\n",
    "    plt.imshow(np.max(np.max(decoded_imgsplo))-decoded_imgsplo.T)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.invert_yaxis()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
