{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90331bNe5Ucu"
   },
   "source": [
    "# Overview\n",
    "\n",
    "The remain of this notebook is organized as follow:\n",
    "- Section 01 contains the cells responsible for testing the CNN model for CSI compression.\n",
    "- Section 02 contains the cells responsible for training the CNN model for CSI compression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGFXradn5DBd"
   },
   "source": [
    "# Section 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U7_lLzaJ66Cb"
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense, BatchNormalization, Reshape, Conv2D, add, LeakyReLU\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.callbacks import TensorBoard, Callback\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E-LT3IJBCRD8"
   },
   "outputs": [],
   "source": [
    "# Set image and network params\n",
    "envir = 'indoor' #'indoor' or 'outdoor'\n",
    "\n",
    "# Image params\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "img_channels = 2 \n",
    "img_total = img_height*img_width*img_channels\n",
    "\n",
    "# Network params\n",
    "residual_num = 2\n",
    "encoded_dim = 512  #compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, compress rate=1/32->dim.=64, compress rate=1/64->dim.=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JjCGizqwCyfi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 15:01:35.712717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:01:35.732264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:01:35.732398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:01:35.732930: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-08 15:01:35.733618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:01:35.733747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:01:35.733842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:01:40.236635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:01:40.237188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:01:40.237679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:01:40.238058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6277 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model and weights\n",
    "file = 'CsiNet_'+(envir)+'_dim'+str(encoded_dim)\n",
    "\n",
    "# Load json and create model\n",
    "outfile = \"files_06_channel/saved_model/model_%s.json\"%file\n",
    "json_file = open(outfile, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "autoencoder = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load weights outto new model\n",
    "outfile = \"files_06_channel/saved_model/model_%s.h5\"%file\n",
    "autoencoder.load_weights(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O2miKM-aDYef"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "if envir == 'indoor':\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_Htestin.mat')\n",
    "  x_test = mat['HT'] # array\n",
    "\n",
    "elif envir == 'outdoor':\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_Htestout.mat')\n",
    "  x_test = mat['HT'] # array\n",
    "\n",
    "x_test = x_test.astype('float32')\n",
    "x_test = np.reshape(x_test, (len(x_test), img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eZyFWM4AD3EM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 15:01:50.329079: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 5s 4ms/step\n",
      "It cost 0.000251 sec\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "tStart = time.time()\n",
    "x_hat = autoencoder.predict(x_test)\n",
    "tEnd = time.time()\n",
    "print (\"It cost %f sec\" % ((tEnd - tStart)/x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "h5c7A8smD_WI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10739/4061624279.py:24: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  n1 = n1.astype('float64')\n",
      "/tmp/ipykernel_10739/4061624279.py:26: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  n2 = n2.astype('float64')\n"
     ]
    }
   ],
   "source": [
    "# Calcaulating the NMSE and rho\n",
    "\n",
    "# Load data with 125 (subcarriers) * 32 (antenna) to calculate rho\n",
    "if envir == 'indoor':\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_HtestFin_all.mat')\n",
    "  X_test = mat['HF_all']# array\n",
    "\n",
    "elif envir == 'outdoor':\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_HtestFout_all.mat')\n",
    "  X_test = mat['HF_all']# array\n",
    "\n",
    "X_test = np.reshape(X_test, (len(X_test), img_height, 125))\n",
    "x_test_real = np.reshape(x_test[:, 0, :, :], (len(x_test), -1))\n",
    "x_test_imag = np.reshape(x_test[:, 1, :, :], (len(x_test), -1))\n",
    "x_test_C = x_test_real-0.5 + 1j*(x_test_imag-0.5)\n",
    "x_hat_real = np.reshape(x_hat[:, 0, :, :], (len(x_hat), -1))\n",
    "x_hat_imag = np.reshape(x_hat[:, 1, :, :], (len(x_hat), -1))\n",
    "x_hat_C = x_hat_real-0.5 + 1j*(x_hat_imag-0.5)\n",
    "x_hat_F = np.reshape(x_hat_C, (len(x_hat_C), img_height, img_width))\n",
    "X_hat = np.fft.fft(np.concatenate((x_hat_F, np.zeros((len(x_hat_C), img_height, 257-img_width))), axis=2), axis=2)\n",
    "X_hat = X_hat[:, :, 0:125]\n",
    "\n",
    "n1 = np.sqrt(np.sum(np.conj(X_test)*X_test, axis=1))\n",
    "n1 = n1.astype('float64')\n",
    "n2 = np.sqrt(np.sum(np.conj(X_hat)*X_hat, axis=1))\n",
    "n2 = n2.astype('float64')\n",
    "aa = abs(np.sum(np.conj(X_test)*X_hat, axis=1))\n",
    "rho = np.mean(aa/(n1*n2), axis=1)\n",
    "X_hat = np.reshape(X_hat, (len(X_hat), -1))\n",
    "X_test = np.reshape(X_test, (len(X_test), -1))\n",
    "power = np.sum(abs(x_test_C)**2, axis=1)\n",
    "power_d = np.sum(abs(X_hat)**2, axis=1)\n",
    "mse = np.sum(abs(x_test_C-x_hat_C)**2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1mPNDSQsEbOr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In indoor environment\n",
      "When dimension is 512\n",
      "NMSE is  -17.36340445785456\n",
      "Correlation is  0.9882019365646585\n"
     ]
    }
   ],
   "source": [
    "print(\"In \"+envir+\" environment\")\n",
    "print(\"When dimension is\", encoded_dim)\n",
    "print(\"NMSE is \", 10*math.log10(np.mean(mse/power)))\n",
    "print(\"Correlation is \", np.mean(rho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oMGFSiVZEqL2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the original and reconstructed pseudo-gray plots of the strength of H\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "  # display original\n",
    "  ax = plt.subplot(2, n, i + 1 )\n",
    "  x_testplo = abs(x_test[i, 0, :, :]-0.5 + 1j*(x_test[i, 1, :, :]-0.5))\n",
    "  plt.imshow(np.max(np.max(x_testplo))-x_testplo.T)\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "  ax.invert_yaxis()\n",
    "  \n",
    "  # display reconstructed\n",
    "  ax = plt.subplot(2, n, i + 1 + n)\n",
    "  decoded_imgsplo = abs(x_hat[i, 0, :, :]-0.5\n",
    "                        + 1j*(x_hat[i, 1, :, :]-0.5))\n",
    "  plt.imshow(np.max(np.max(decoded_imgsplo))-decoded_imgsplo.T)\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "  ax.invert_yaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtRCCt3l6pOV"
   },
   "source": [
    "# Section 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2erDuVef6_KO"
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense, BatchNormalization, Reshape, Conv2D, add, LeakyReLU\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.callbacks import TensorBoard, Callback\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IqXCkcfo7OPL"
   },
   "outputs": [],
   "source": [
    "# Set image and network params\n",
    "envir = 'indoor' #'indoor' or 'outdoor'\n",
    "\n",
    "# Image params\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "img_channels = 2 \n",
    "img_total = img_height*img_width*img_channels\n",
    "\n",
    "# Network params\n",
    "residual_num = 2\n",
    "encoded_dim = 512  #compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, compress rate=1/32->dim.=64, compress rate=1/64->dim.=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mnOkmZjU7RI6"
   },
   "outputs": [],
   "source": [
    "# Bulid the autoencoder model (CNN model) of CsiNet\n",
    "def residual_network(x, residual_num, encoded_dim):\n",
    "  def add_common_layers(y):\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    \n",
    "    return y\n",
    "  \n",
    "  def residual_block_decoded(y):\n",
    "    shortcut = y\n",
    "    y = Conv2D(8, kernel_size=(3, 3), padding='same', data_format='channels_first')(y)\n",
    "    y = add_common_layers(y)\n",
    "    \n",
    "    y = Conv2D(16, kernel_size=(3, 3), padding='same', data_format='channels_first')(y)\n",
    "    y = add_common_layers(y)\n",
    "    \n",
    "    y = Conv2D(2, kernel_size=(3, 3), padding='same', data_format='channels_first')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    y = add([shortcut, y])\n",
    "    y = LeakyReLU()(y)\n",
    "\n",
    "    return y\n",
    "  \n",
    "  x = Conv2D(2, (3, 3), padding='same', data_format=\"channels_first\")(x)\n",
    "  x = add_common_layers(x)\n",
    "  \n",
    "  x = Reshape((img_total,))(x)\n",
    "  encoded = Dense(encoded_dim, activation='linear')(x)\n",
    "  \n",
    "  x = Dense(img_total, activation='linear')(encoded)\n",
    "  x = Reshape((img_channels, img_height, img_width,))(x)\n",
    "  for i in range(residual_num):\n",
    "    x = residual_block_decoded(x)\n",
    "  \n",
    "  x = Conv2D(2, (3, 3), activation='sigmoid', padding='same', data_format=\"channels_first\")(x)\n",
    "  \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "H8DnkqPe8IXw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2, 32, 32)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 2, 32, 32)    38          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 2, 32, 32)   128         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 2, 32, 32)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 2048)         0           ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          1049088     ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2048)         1050624     ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 2, 32, 32)    0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 32, 32)    152         ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 8, 32, 32)   128         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 8, 32, 32)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 16, 32, 32)   1168        ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 16, 32, 32)  128         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 16, 32, 32)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 2, 32, 32)    290         ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 2, 32, 32)   128         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 2, 32, 32)    0           ['reshape_1[0][0]',              \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 2, 32, 32)    0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 8, 32, 32)    152         ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 8, 32, 32)   128         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 8, 32, 32)    0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 32, 32)   1168        ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 32, 32)  128         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 16, 32, 32)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 2, 32, 32)    290         ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 2, 32, 32)   128         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 2, 32, 32)    0           ['leaky_re_lu_3[0][0]',          \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 2, 32, 32)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 2, 32, 32)    38          ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,103,904\n",
      "Trainable params: 2,103,456\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 15:03:41.544518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:03:41.563541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:03:41.563706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:03:41.564453: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-08 15:03:41.564785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:03:41.564909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:03:41.565003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:03:42.066349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:03:42.066478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:03:42.066575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:03:42.066657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6248 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Set autoencoder model params and display the network model\n",
    "image_tensor = Input(shape=(img_channels, img_height, img_width))\n",
    "network_output = residual_network(image_tensor, residual_num, encoded_dim)\n",
    "autoencoder = Model(inputs=[image_tensor], outputs=[network_output])\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "meKKoN-f8Z80"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "if envir == 'indoor':\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_Htrainin.mat') \n",
    "  x_train = mat['HT'] # array\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_Hvalin.mat')\n",
    "  x_val = mat['HT'] # array\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_Htestin.mat')\n",
    "  x_test = mat['HT'] # array\n",
    "\n",
    "elif envir == 'outdoor':\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_Htrainout.mat') \n",
    "  x_train = mat['HT'] # array\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_Hvalout.mat')\n",
    "  x_val = mat['HT'] # array\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_Htestout.mat')\n",
    "  x_test = mat['HT'] # array\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = np.reshape(x_train, (len(x_train), img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\n",
    "x_val = np.reshape(x_val, (len(x_val), img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qm9CimNI9h4c"
   },
   "outputs": [],
   "source": [
    "# Create a class to save the loss history of the model\n",
    "class LossHistory(Callback):\n",
    "  def on_train_begin(self, logs={}):\n",
    "    self.losses_train = []\n",
    "    self.losses_val = []\n",
    "  \n",
    "  def on_batch_end(self, batch, logs={}):\n",
    "    self.losses_train.append(logs.get('loss'))    \n",
    "    \n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    self.losses_val.append(logs.get('val_loss'))\n",
    "\n",
    "history = LossHistory()\n",
    "file = 'CsiNet_'+(envir)+'_dim'+str(encoded_dim)+time.strftime('_%m_%d')\n",
    "path = 'files_06_channel/result/TensorBoard_%s' %file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PVFELTj_9uKl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 15:04:27.943380: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/500 [..............................] - ETA: 6s - loss: 0.0341   WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0041s vs `on_train_batch_end` time: 0.0111s). Check your callbacks.\n",
      "500/500 [==============================] - 10s 14ms/step - loss: 0.0011 - val_loss: 4.4028e-04\n",
      "Epoch 2/1000\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 3.9288e-04 - val_loss: 3.7147e-04\n",
      "Epoch 3/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.4348e-04 - val_loss: 3.2810e-04\n",
      "Epoch 4/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.0030e-04 - val_loss: 2.8851e-04\n",
      "Epoch 5/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.5925e-04 - val_loss: 2.4718e-04\n",
      "Epoch 6/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.2471e-04 - val_loss: 2.0936e-04\n",
      "Epoch 7/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.9814e-04 - val_loss: 1.9086e-04\n",
      "Epoch 8/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.7697e-04 - val_loss: 1.7812e-04\n",
      "Epoch 9/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.5996e-04 - val_loss: 1.6613e-04\n",
      "Epoch 10/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.4586e-04 - val_loss: 1.5607e-04\n",
      "Epoch 11/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3364e-04 - val_loss: 1.5069e-04\n",
      "Epoch 12/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2352e-04 - val_loss: 1.4340e-04\n",
      "Epoch 13/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.1795e-04 - val_loss: 1.8288e-04\n",
      "Epoch 14/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2256e-04 - val_loss: 1.1459e-04\n",
      "Epoch 15/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0761e-04 - val_loss: 1.0817e-04\n",
      "Epoch 16/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0099e-04 - val_loss: 9.9868e-05\n",
      "Epoch 17/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.4500e-05 - val_loss: 9.5581e-05\n",
      "Epoch 18/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.9211e-05 - val_loss: 9.1045e-05\n",
      "Epoch 19/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.4241e-05 - val_loss: 9.2151e-05\n",
      "Epoch 20/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.0560e-04 - val_loss: 1.5443e-04\n",
      "Epoch 21/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.2463e-05 - val_loss: 8.8304e-05\n",
      "Epoch 22/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.1461e-05 - val_loss: 8.0022e-05\n",
      "Epoch 23/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.6354e-05 - val_loss: 7.7047e-05\n",
      "Epoch 24/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2779e-05 - val_loss: 7.5212e-05\n",
      "Epoch 25/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9380e-05 - val_loss: 7.2738e-05\n",
      "Epoch 26/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6237e-05 - val_loss: 7.4028e-05\n",
      "Epoch 27/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3139e-05 - val_loss: 7.0838e-05\n",
      "Epoch 28/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.3012e-04 - val_loss: 1.6795e-04\n",
      "Epoch 29/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.0133e-05 - val_loss: 8.6065e-05\n",
      "Epoch 30/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2924e-05 - val_loss: 7.5280e-05\n",
      "Epoch 31/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6453e-05 - val_loss: 6.4830e-05\n",
      "Epoch 32/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2689e-05 - val_loss: 6.1731e-05\n",
      "Epoch 33/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9306e-05 - val_loss: 5.8926e-05\n",
      "Epoch 34/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.6672e-05 - val_loss: 5.8790e-05\n",
      "Epoch 35/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.4709e-05 - val_loss: 5.4376e-05\n",
      "Epoch 36/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.2185e-05 - val_loss: 5.1188e-05\n",
      "Epoch 37/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.0167e-05 - val_loss: 5.1455e-05\n",
      "Epoch 38/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 4.8135e-05 - val_loss: 5.1320e-05\n",
      "Epoch 39/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 4.6536e-05 - val_loss: 5.1163e-05\n",
      "Epoch 40/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.6573e-04 - val_loss: 2.9458e-04\n",
      "Epoch 41/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.9446e-04 - val_loss: 1.6788e-04\n",
      "Epoch 42/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2988e-04 - val_loss: 1.1892e-04\n",
      "Epoch 43/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0165e-04 - val_loss: 9.7294e-05\n",
      "Epoch 44/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.5535e-05 - val_loss: 8.0130e-05\n",
      "Epoch 45/1000\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 7.5125e-05 - val_loss: 7.2501e-05\n",
      "Epoch 46/1000\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 6.7657e-05 - val_loss: 6.5638e-05\n",
      "Epoch 47/1000\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 6.2046e-05 - val_loss: 6.2130e-05\n",
      "Epoch 48/1000\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.7873e-05 - val_loss: 5.5500e-05\n",
      "Epoch 49/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.4226e-05 - val_loss: 5.1883e-05\n",
      "Epoch 50/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.1541e-05 - val_loss: 4.9834e-05\n",
      "Epoch 51/1000\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 4.8730e-05 - val_loss: 5.0413e-05\n",
      "Epoch 52/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.5626e-04 - val_loss: 3.7614e-04\n",
      "Epoch 53/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.2589e-04 - val_loss: 2.6352e-04\n",
      "Epoch 54/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.5256e-04 - val_loss: 1.7174e-04\n",
      "Epoch 55/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1554e-04 - val_loss: 1.2525e-04\n",
      "Epoch 56/1000\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 9.2724e-05 - val_loss: 9.7501e-05\n",
      "Epoch 57/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.6567e-05 - val_loss: 7.2980e-05\n",
      "Epoch 58/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7532e-05 - val_loss: 6.2856e-05\n",
      "Epoch 59/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1825e-05 - val_loss: 5.8225e-05\n",
      "Epoch 60/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.7440e-05 - val_loss: 5.4984e-05\n",
      "Epoch 61/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.3858e-05 - val_loss: 5.2213e-05\n",
      "Epoch 62/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.0729e-05 - val_loss: 5.4166e-05\n",
      "Epoch 63/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 4.8644e-05 - val_loss: 4.5915e-05\n",
      "Epoch 64/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 4.5944e-05 - val_loss: 4.4821e-05\n",
      "Epoch 65/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.3851e-04 - val_loss: 3.5508e-04\n",
      "Epoch 66/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.9254e-04 - val_loss: 2.2783e-04\n",
      "Epoch 67/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2388e-04 - val_loss: 1.5091e-04\n",
      "Epoch 68/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.8573e-05 - val_loss: 9.3341e-05\n",
      "Epoch 69/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0428e-05 - val_loss: 6.7608e-05\n",
      "Epoch 70/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1016e-05 - val_loss: 5.8756e-05\n",
      "Epoch 71/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.5849e-05 - val_loss: 5.3803e-05\n",
      "Epoch 72/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 7s 13ms/step - loss: 5.1420e-05 - val_loss: 5.0841e-05\n",
      "Epoch 73/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 4.8472e-05 - val_loss: 4.7842e-05\n",
      "Epoch 74/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 4.6133e-05 - val_loss: 4.6827e-05\n",
      "Epoch 75/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 4.4236e-05 - val_loss: 4.4616e-05\n",
      "Epoch 76/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 4.2809e-05 - val_loss: 4.1620e-05\n",
      "Epoch 77/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 4.1017e-05 - val_loss: 4.0179e-05\n",
      "Epoch 78/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.9792e-05 - val_loss: 3.7821e-05\n",
      "Epoch 79/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.8409e-05 - val_loss: 4.0822e-05\n",
      "Epoch 80/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.7289e-05 - val_loss: 3.6540e-05\n",
      "Epoch 81/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.6133e-05 - val_loss: 3.5821e-05\n",
      "Epoch 82/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.4959e-05 - val_loss: 3.3746e-05\n",
      "Epoch 83/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.4150e-05 - val_loss: 3.5294e-05\n",
      "Epoch 84/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.3023e-05 - val_loss: 3.2640e-05\n",
      "Epoch 85/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.6236e-04 - val_loss: 4.8298e-04\n",
      "Epoch 86/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.7500e-04 - val_loss: 2.4563e-04\n",
      "Epoch 87/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.2183e-05 - val_loss: 7.8707e-05\n",
      "Epoch 88/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.8369e-05 - val_loss: 5.7236e-05\n",
      "Epoch 89/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 4.8956e-05 - val_loss: 4.6427e-05\n",
      "Epoch 90/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 4.3729e-05 - val_loss: 4.0656e-05\n",
      "Epoch 91/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.9708e-05 - val_loss: 3.9955e-05\n",
      "Epoch 92/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.7322e-05 - val_loss: 3.5592e-05\n",
      "Epoch 93/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.5622e-05 - val_loss: 3.4862e-05\n",
      "Epoch 94/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.3978e-05 - val_loss: 3.1697e-05\n",
      "Epoch 95/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.2628e-05 - val_loss: 3.2494e-05\n",
      "Epoch 96/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.1357e-05 - val_loss: 3.1751e-05\n",
      "Epoch 97/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.0263e-05 - val_loss: 2.9693e-05\n",
      "Epoch 98/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.9548e-05 - val_loss: 2.8582e-05\n",
      "Epoch 99/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.8671e-05 - val_loss: 2.7183e-05\n",
      "Epoch 100/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.7860e-05 - val_loss: 2.7252e-05\n",
      "Epoch 101/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.7041e-05 - val_loss: 2.5416e-05\n",
      "Epoch 102/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.6368e-05 - val_loss: 2.5026e-05\n",
      "Epoch 103/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.5810e-05 - val_loss: 2.6732e-05\n",
      "Epoch 104/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.5351e-05 - val_loss: 2.7907e-05\n",
      "Epoch 105/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.4713e-05 - val_loss: 2.4969e-05\n",
      "Epoch 106/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.4338e-05 - val_loss: 2.3408e-05\n",
      "Epoch 107/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.3905e-05 - val_loss: 2.3043e-05\n",
      "Epoch 108/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.3376e-05 - val_loss: 2.4133e-05\n",
      "Epoch 109/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2011e-04 - val_loss: 5.5418e-05\n",
      "Epoch 110/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 3.4528e-05 - val_loss: 3.2337e-05\n",
      "Epoch 111/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.8781e-05 - val_loss: 2.8623e-05\n",
      "Epoch 112/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.6999e-05 - val_loss: 2.6411e-05\n",
      "Epoch 113/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.5278e-05 - val_loss: 2.5720e-05\n",
      "Epoch 114/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.4504e-05 - val_loss: 2.5251e-05\n",
      "Epoch 115/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.3506e-05 - val_loss: 2.2690e-05\n",
      "Epoch 116/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.3011e-05 - val_loss: 2.2383e-05\n",
      "Epoch 117/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.2324e-05 - val_loss: 2.1840e-05\n",
      "Epoch 118/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.1905e-05 - val_loss: 2.1945e-05\n",
      "Epoch 119/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.1415e-05 - val_loss: 2.1510e-05\n",
      "Epoch 120/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.0911e-05 - val_loss: 2.0666e-05\n",
      "Epoch 121/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.0614e-05 - val_loss: 1.9324e-05\n",
      "Epoch 122/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.0175e-05 - val_loss: 2.0610e-05\n",
      "Epoch 123/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.0050e-05 - val_loss: 1.9422e-05\n",
      "Epoch 124/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.9634e-05 - val_loss: 1.9601e-05\n",
      "Epoch 125/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.9538e-05 - val_loss: 2.0271e-05\n",
      "Epoch 126/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.8961e-05 - val_loss: 1.9297e-05\n",
      "Epoch 127/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.8794e-05 - val_loss: 1.8348e-05\n",
      "Epoch 128/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.8666e-05 - val_loss: 1.7172e-05\n",
      "Epoch 129/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.8361e-05 - val_loss: 1.9687e-05\n",
      "Epoch 130/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.8236e-05 - val_loss: 1.8319e-05\n",
      "Epoch 131/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.7913e-05 - val_loss: 1.6798e-05\n",
      "Epoch 132/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.7783e-05 - val_loss: 1.8214e-05\n",
      "Epoch 133/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.7579e-05 - val_loss: 1.9391e-05\n",
      "Epoch 134/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.7488e-05 - val_loss: 1.7892e-05\n",
      "Epoch 135/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.7419e-05 - val_loss: 1.7117e-05\n",
      "Epoch 136/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.7088e-05 - val_loss: 1.6730e-05\n",
      "Epoch 137/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.6978e-05 - val_loss: 1.7515e-05\n",
      "Epoch 138/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.6850e-05 - val_loss: 1.5928e-05\n",
      "Epoch 139/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.6687e-05 - val_loss: 1.6442e-05\n",
      "Epoch 140/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.6583e-05 - val_loss: 1.7079e-05\n",
      "Epoch 141/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.6485e-05 - val_loss: 1.6831e-05\n",
      "Epoch 142/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.6237e-05 - val_loss: 1.6962e-05\n",
      "Epoch 143/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.6012e-05 - val_loss: 1.6957e-05\n",
      "Epoch 144/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.6088e-05 - val_loss: 1.5690e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.5859e-05 - val_loss: 1.5468e-05\n",
      "Epoch 146/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.5698e-05 - val_loss: 1.4914e-05\n",
      "Epoch 147/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.5668e-05 - val_loss: 1.7928e-05\n",
      "Epoch 148/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.5469e-05 - val_loss: 1.6114e-05\n",
      "Epoch 149/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.5364e-05 - val_loss: 1.5986e-05\n",
      "Epoch 150/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.5372e-05 - val_loss: 1.5955e-05\n",
      "Epoch 151/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.5170e-05 - val_loss: 1.4317e-05\n",
      "Epoch 152/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.5019e-05 - val_loss: 1.6056e-05\n",
      "Epoch 153/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.5148e-05 - val_loss: 1.5249e-05\n",
      "Epoch 154/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.4886e-05 - val_loss: 1.4625e-05\n",
      "Epoch 155/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.4859e-05 - val_loss: 1.5062e-05\n",
      "Epoch 156/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.4950e-05 - val_loss: 1.5894e-05\n",
      "Epoch 157/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.4508e-05 - val_loss: 1.5428e-05\n",
      "Epoch 158/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.4539e-05 - val_loss: 1.4786e-05\n",
      "Epoch 159/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.4653e-05 - val_loss: 1.4971e-05\n",
      "Epoch 160/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.4336e-05 - val_loss: 1.4996e-05\n",
      "Epoch 161/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.4449e-05 - val_loss: 1.3974e-05\n",
      "Epoch 162/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.4224e-05 - val_loss: 1.4152e-05\n",
      "Epoch 163/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.4253e-05 - val_loss: 1.4297e-05\n",
      "Epoch 164/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.4124e-05 - val_loss: 1.5422e-05\n",
      "Epoch 165/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3943e-05 - val_loss: 1.4878e-05\n",
      "Epoch 166/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.4043e-05 - val_loss: 1.4536e-05\n",
      "Epoch 167/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3980e-05 - val_loss: 1.4700e-05\n",
      "Epoch 168/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3848e-05 - val_loss: 1.4586e-05\n",
      "Epoch 169/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3793e-05 - val_loss: 1.4805e-05\n",
      "Epoch 170/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3723e-05 - val_loss: 1.4215e-05\n",
      "Epoch 171/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3682e-05 - val_loss: 1.3569e-05\n",
      "Epoch 172/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3656e-05 - val_loss: 1.6033e-05\n",
      "Epoch 173/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3525e-05 - val_loss: 1.3995e-05\n",
      "Epoch 174/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3400e-05 - val_loss: 1.3810e-05\n",
      "Epoch 175/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3387e-05 - val_loss: 1.3700e-05\n",
      "Epoch 176/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3321e-05 - val_loss: 1.3033e-05\n",
      "Epoch 177/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3323e-05 - val_loss: 1.3278e-05\n",
      "Epoch 178/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3252e-05 - val_loss: 1.3061e-05\n",
      "Epoch 179/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3134e-05 - val_loss: 1.3505e-05\n",
      "Epoch 180/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3118e-05 - val_loss: 1.3197e-05\n",
      "Epoch 181/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3073e-05 - val_loss: 1.3189e-05\n",
      "Epoch 182/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3080e-05 - val_loss: 1.4710e-05\n",
      "Epoch 183/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.3021e-05 - val_loss: 1.3895e-05\n",
      "Epoch 184/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2955e-05 - val_loss: 1.2440e-05\n",
      "Epoch 185/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2845e-05 - val_loss: 1.3719e-05\n",
      "Epoch 186/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2784e-05 - val_loss: 1.2735e-05\n",
      "Epoch 187/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2744e-05 - val_loss: 1.3322e-05\n",
      "Epoch 188/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2684e-05 - val_loss: 1.3147e-05\n",
      "Epoch 189/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2728e-05 - val_loss: 1.2171e-05\n",
      "Epoch 190/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2603e-05 - val_loss: 1.3210e-05\n",
      "Epoch 191/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2531e-05 - val_loss: 1.2318e-05\n",
      "Epoch 192/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2539e-05 - val_loss: 1.3583e-05\n",
      "Epoch 193/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2433e-05 - val_loss: 1.4394e-05\n",
      "Epoch 194/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2516e-05 - val_loss: 1.3086e-05\n",
      "Epoch 195/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2390e-05 - val_loss: 1.2524e-05\n",
      "Epoch 196/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2346e-05 - val_loss: 1.2941e-05\n",
      "Epoch 197/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2379e-05 - val_loss: 1.2411e-05\n",
      "Epoch 198/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2302e-05 - val_loss: 1.4161e-05\n",
      "Epoch 199/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2358e-05 - val_loss: 1.2019e-05\n",
      "Epoch 200/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2170e-05 - val_loss: 1.2317e-05\n",
      "Epoch 201/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2200e-05 - val_loss: 1.2359e-05\n",
      "Epoch 202/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2152e-05 - val_loss: 1.3109e-05\n",
      "Epoch 203/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2167e-05 - val_loss: 1.2254e-05\n",
      "Epoch 204/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2175e-05 - val_loss: 1.2971e-05\n",
      "Epoch 205/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2063e-05 - val_loss: 1.1810e-05\n",
      "Epoch 206/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1973e-05 - val_loss: 1.2808e-05\n",
      "Epoch 207/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1999e-05 - val_loss: 1.2447e-05\n",
      "Epoch 208/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1935e-05 - val_loss: 1.3710e-05\n",
      "Epoch 209/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1979e-05 - val_loss: 1.2659e-05\n",
      "Epoch 210/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1880e-05 - val_loss: 1.3204e-05\n",
      "Epoch 211/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1805e-05 - val_loss: 1.2887e-05\n",
      "Epoch 212/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1850e-05 - val_loss: 1.2312e-05\n",
      "Epoch 213/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1660e-05 - val_loss: 1.2420e-05\n",
      "Epoch 214/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1730e-05 - val_loss: 1.1812e-05\n",
      "Epoch 215/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1687e-05 - val_loss: 1.1739e-05\n",
      "Epoch 216/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1732e-05 - val_loss: 1.1620e-05\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1643e-05 - val_loss: 1.1550e-05\n",
      "Epoch 218/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1554e-05 - val_loss: 1.1944e-05\n",
      "Epoch 219/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1572e-05 - val_loss: 1.2942e-05\n",
      "Epoch 220/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1560e-05 - val_loss: 1.2084e-05\n",
      "Epoch 221/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1435e-05 - val_loss: 1.2001e-05\n",
      "Epoch 222/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1473e-05 - val_loss: 1.1369e-05\n",
      "Epoch 223/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1328e-05 - val_loss: 1.2286e-05\n",
      "Epoch 224/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1431e-05 - val_loss: 1.1928e-05\n",
      "Epoch 225/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1381e-05 - val_loss: 1.2314e-05\n",
      "Epoch 226/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1527e-05 - val_loss: 1.1612e-05\n",
      "Epoch 227/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1250e-05 - val_loss: 1.1466e-05\n",
      "Epoch 228/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1307e-05 - val_loss: 1.1703e-05\n",
      "Epoch 229/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1301e-05 - val_loss: 1.0978e-05\n",
      "Epoch 230/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1349e-05 - val_loss: 1.1571e-05\n",
      "Epoch 231/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1157e-05 - val_loss: 1.1474e-05\n",
      "Epoch 232/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1214e-05 - val_loss: 1.3848e-05\n",
      "Epoch 233/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1321e-05 - val_loss: 1.2389e-05\n",
      "Epoch 234/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1140e-05 - val_loss: 1.2006e-05\n",
      "Epoch 235/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1220e-05 - val_loss: 1.1590e-05\n",
      "Epoch 236/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1144e-05 - val_loss: 1.1367e-05\n",
      "Epoch 237/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1059e-05 - val_loss: 1.1532e-05\n",
      "Epoch 238/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1097e-05 - val_loss: 1.1874e-05\n",
      "Epoch 239/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1045e-05 - val_loss: 1.2057e-05\n",
      "Epoch 240/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1027e-05 - val_loss: 1.0634e-05\n",
      "Epoch 241/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0880e-05 - val_loss: 1.1454e-05\n",
      "Epoch 242/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0957e-05 - val_loss: 1.2052e-05\n",
      "Epoch 243/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1042e-05 - val_loss: 1.1207e-05\n",
      "Epoch 244/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0831e-05 - val_loss: 1.1142e-05\n",
      "Epoch 245/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0954e-05 - val_loss: 1.1668e-05\n",
      "Epoch 246/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0840e-05 - val_loss: 1.1222e-05\n",
      "Epoch 247/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0911e-05 - val_loss: 1.1894e-05\n",
      "Epoch 248/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0842e-05 - val_loss: 1.1396e-05\n",
      "Epoch 249/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0884e-05 - val_loss: 1.1959e-05\n",
      "Epoch 250/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0828e-05 - val_loss: 1.0776e-05\n",
      "Epoch 251/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0707e-05 - val_loss: 1.1509e-05\n",
      "Epoch 252/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0804e-05 - val_loss: 1.1731e-05\n",
      "Epoch 253/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0748e-05 - val_loss: 1.1873e-05\n",
      "Epoch 254/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0771e-05 - val_loss: 1.0828e-05\n",
      "Epoch 255/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0690e-05 - val_loss: 1.1409e-05\n",
      "Epoch 256/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0600e-05 - val_loss: 1.1218e-05\n",
      "Epoch 257/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0675e-05 - val_loss: 1.0745e-05\n",
      "Epoch 258/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0651e-05 - val_loss: 1.1149e-05\n",
      "Epoch 259/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0560e-05 - val_loss: 1.2474e-05\n",
      "Epoch 260/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0634e-05 - val_loss: 1.1341e-05\n",
      "Epoch 261/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0565e-05 - val_loss: 1.1555e-05\n",
      "Epoch 262/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0487e-05 - val_loss: 1.1422e-05\n",
      "Epoch 263/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0533e-05 - val_loss: 1.2064e-05\n",
      "Epoch 264/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0481e-05 - val_loss: 1.0726e-05\n",
      "Epoch 265/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0430e-05 - val_loss: 1.0418e-05\n",
      "Epoch 266/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0508e-05 - val_loss: 1.0185e-05\n",
      "Epoch 267/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0453e-05 - val_loss: 1.0906e-05\n",
      "Epoch 268/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0379e-05 - val_loss: 1.1662e-05\n",
      "Epoch 269/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0411e-05 - val_loss: 1.0670e-05\n",
      "Epoch 270/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0409e-05 - val_loss: 1.0677e-05\n",
      "Epoch 271/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0390e-05 - val_loss: 1.0340e-05\n",
      "Epoch 272/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0328e-05 - val_loss: 1.1187e-05\n",
      "Epoch 273/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0274e-05 - val_loss: 1.1414e-05\n",
      "Epoch 274/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0308e-05 - val_loss: 1.1257e-05\n",
      "Epoch 275/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0178e-05 - val_loss: 1.0829e-05\n",
      "Epoch 276/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0234e-05 - val_loss: 1.0741e-05\n",
      "Epoch 277/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0325e-05 - val_loss: 1.0927e-05\n",
      "Epoch 278/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0229e-05 - val_loss: 1.0581e-05\n",
      "Epoch 279/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0230e-05 - val_loss: 1.0328e-05\n",
      "Epoch 280/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0161e-05 - val_loss: 1.0617e-05\n",
      "Epoch 281/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0199e-05 - val_loss: 1.1067e-05\n",
      "Epoch 282/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0080e-05 - val_loss: 1.0891e-05\n",
      "Epoch 283/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0213e-05 - val_loss: 1.0419e-05\n",
      "Epoch 284/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0117e-05 - val_loss: 1.0405e-05\n",
      "Epoch 285/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0185e-05 - val_loss: 9.9146e-06\n",
      "Epoch 286/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0040e-05 - val_loss: 1.0634e-05\n",
      "Epoch 287/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0060e-05 - val_loss: 1.0310e-05\n",
      "Epoch 288/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0126e-05 - val_loss: 1.1745e-05\n",
      "Epoch 289/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0079e-05 - val_loss: 1.0166e-05\n",
      "Epoch 290/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0119e-05 - val_loss: 9.7438e-06\n",
      "Epoch 291/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0010e-05 - val_loss: 1.0055e-05\n",
      "Epoch 292/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.9889e-06 - val_loss: 1.0452e-05\n",
      "Epoch 293/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.9092e-06 - val_loss: 1.1138e-05\n",
      "Epoch 294/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0021e-05 - val_loss: 1.0085e-05\n",
      "Epoch 295/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0029e-05 - val_loss: 1.0336e-05\n",
      "Epoch 296/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.9172e-06 - val_loss: 1.0100e-05\n",
      "Epoch 297/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.9174e-06 - val_loss: 1.1893e-05\n",
      "Epoch 298/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.8807e-06 - val_loss: 9.8075e-06\n",
      "Epoch 299/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.8775e-06 - val_loss: 1.0370e-05\n",
      "Epoch 300/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.7921e-06 - val_loss: 1.0489e-05\n",
      "Epoch 301/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.9085e-06 - val_loss: 1.0050e-05\n",
      "Epoch 302/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.8867e-06 - val_loss: 1.0225e-05\n",
      "Epoch 303/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.8210e-06 - val_loss: 9.3741e-06\n",
      "Epoch 304/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.7294e-06 - val_loss: 9.8742e-06\n",
      "Epoch 305/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.8587e-06 - val_loss: 1.0599e-05\n",
      "Epoch 306/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.8189e-06 - val_loss: 1.0418e-05\n",
      "Epoch 307/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.7205e-06 - val_loss: 1.0522e-05\n",
      "Epoch 308/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.6862e-06 - val_loss: 1.0130e-05\n",
      "Epoch 309/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.7327e-06 - val_loss: 1.0074e-05\n",
      "Epoch 310/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.6835e-06 - val_loss: 9.4048e-06\n",
      "Epoch 311/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.6291e-06 - val_loss: 9.5868e-06\n",
      "Epoch 312/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.7741e-06 - val_loss: 9.8179e-06\n",
      "Epoch 313/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.6101e-06 - val_loss: 1.1211e-05\n",
      "Epoch 314/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.6860e-06 - val_loss: 1.0029e-05\n",
      "Epoch 315/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.6849e-06 - val_loss: 9.3173e-06\n",
      "Epoch 316/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.6206e-06 - val_loss: 1.0012e-05\n",
      "Epoch 317/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.6201e-06 - val_loss: 9.4603e-06\n",
      "Epoch 318/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.5807e-06 - val_loss: 9.6212e-06\n",
      "Epoch 319/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.5232e-06 - val_loss: 1.0722e-05\n",
      "Epoch 320/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.5832e-06 - val_loss: 1.0517e-05\n",
      "Epoch 321/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.6224e-06 - val_loss: 1.1848e-05\n",
      "Epoch 322/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.4882e-06 - val_loss: 1.0187e-05\n",
      "Epoch 323/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.4248e-06 - val_loss: 1.0305e-05\n",
      "Epoch 324/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.5760e-06 - val_loss: 9.4537e-06\n",
      "Epoch 325/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.4528e-06 - val_loss: 1.0129e-05\n",
      "Epoch 326/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.5237e-06 - val_loss: 9.5895e-06\n",
      "Epoch 327/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.4048e-06 - val_loss: 9.7475e-06\n",
      "Epoch 328/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.4128e-06 - val_loss: 9.9345e-06\n",
      "Epoch 329/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.4144e-06 - val_loss: 9.6573e-06\n",
      "Epoch 330/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.4434e-06 - val_loss: 1.0127e-05\n",
      "Epoch 331/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.3335e-06 - val_loss: 1.0011e-05\n",
      "Epoch 332/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.3974e-06 - val_loss: 1.0053e-05\n",
      "Epoch 333/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.4230e-06 - val_loss: 9.9910e-06\n",
      "Epoch 334/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.4244e-06 - val_loss: 9.6976e-06\n",
      "Epoch 335/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.3810e-06 - val_loss: 9.0959e-06\n",
      "Epoch 336/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.3032e-06 - val_loss: 9.5449e-06\n",
      "Epoch 337/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.3143e-06 - val_loss: 9.7941e-06\n",
      "Epoch 338/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.2973e-06 - val_loss: 9.8533e-06\n",
      "Epoch 339/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.3299e-06 - val_loss: 1.0353e-05\n",
      "Epoch 340/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.3140e-06 - val_loss: 9.6552e-06\n",
      "Epoch 341/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.2874e-06 - val_loss: 9.5684e-06\n",
      "Epoch 342/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.2905e-06 - val_loss: 9.4962e-06\n",
      "Epoch 343/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.2696e-06 - val_loss: 9.3692e-06\n",
      "Epoch 344/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.2204e-06 - val_loss: 1.0371e-05\n",
      "Epoch 345/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.2046e-06 - val_loss: 9.1899e-06\n",
      "Epoch 346/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.1476e-06 - val_loss: 9.4338e-06\n",
      "Epoch 347/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.2347e-06 - val_loss: 1.0442e-05\n",
      "Epoch 348/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.1752e-06 - val_loss: 9.4067e-06\n",
      "Epoch 349/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.1269e-06 - val_loss: 1.0054e-05\n",
      "Epoch 350/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.1184e-06 - val_loss: 9.3604e-06\n",
      "Epoch 351/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.2052e-06 - val_loss: 9.7522e-06\n",
      "Epoch 352/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.0905e-06 - val_loss: 9.3698e-06\n",
      "Epoch 353/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.0970e-06 - val_loss: 9.2180e-06\n",
      "Epoch 354/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.1370e-06 - val_loss: 9.7818e-06\n",
      "Epoch 355/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.1275e-06 - val_loss: 9.6761e-06\n",
      "Epoch 356/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.0562e-06 - val_loss: 9.3857e-06\n",
      "Epoch 357/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.0180e-06 - val_loss: 1.0423e-05\n",
      "Epoch 358/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.0973e-06 - val_loss: 9.5392e-06\n",
      "Epoch 359/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.9992e-06 - val_loss: 9.1866e-06\n",
      "Epoch 360/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.0407e-06 - val_loss: 9.6011e-06\n",
      "Epoch 361/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 7s 13ms/step - loss: 9.1118e-06 - val_loss: 9.6884e-06\n",
      "Epoch 362/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.0206e-06 - val_loss: 9.1259e-06\n",
      "Epoch 363/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 9.0886e-06 - val_loss: 1.0669e-05\n",
      "Epoch 364/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.9350e-06 - val_loss: 9.7983e-06\n",
      "Epoch 365/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.9971e-06 - val_loss: 1.0166e-05\n",
      "Epoch 366/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.9853e-06 - val_loss: 9.2840e-06\n",
      "Epoch 367/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.9863e-06 - val_loss: 9.6326e-06\n",
      "Epoch 368/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.9496e-06 - val_loss: 9.2998e-06\n",
      "Epoch 369/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.9170e-06 - val_loss: 9.1130e-06\n",
      "Epoch 370/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.9644e-06 - val_loss: 9.2172e-06\n",
      "Epoch 371/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.9253e-06 - val_loss: 9.5823e-06\n",
      "Epoch 372/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.9527e-06 - val_loss: 8.8804e-06\n",
      "Epoch 373/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.9082e-06 - val_loss: 9.2955e-06\n",
      "Epoch 374/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.9306e-06 - val_loss: 9.2594e-06\n",
      "Epoch 375/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.8600e-06 - val_loss: 1.0014e-05\n",
      "Epoch 376/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.8815e-06 - val_loss: 9.0202e-06\n",
      "Epoch 377/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.8621e-06 - val_loss: 9.2063e-06\n",
      "Epoch 378/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.8472e-06 - val_loss: 9.3979e-06\n",
      "Epoch 379/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.8055e-06 - val_loss: 8.6545e-06\n",
      "Epoch 380/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.8444e-06 - val_loss: 9.2281e-06\n",
      "Epoch 381/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.7670e-06 - val_loss: 9.5671e-06\n",
      "Epoch 382/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.7861e-06 - val_loss: 9.3602e-06\n",
      "Epoch 383/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.7495e-06 - val_loss: 9.2669e-06\n",
      "Epoch 384/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.8222e-06 - val_loss: 1.0066e-05\n",
      "Epoch 385/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.8201e-06 - val_loss: 9.5519e-06\n",
      "Epoch 386/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.7382e-06 - val_loss: 8.4723e-06\n",
      "Epoch 387/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.7568e-06 - val_loss: 9.7738e-06\n",
      "Epoch 388/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.7329e-06 - val_loss: 9.3944e-06\n",
      "Epoch 389/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.7307e-06 - val_loss: 9.3514e-06\n",
      "Epoch 390/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.7190e-06 - val_loss: 8.9440e-06\n",
      "Epoch 391/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.6915e-06 - val_loss: 8.9406e-06\n",
      "Epoch 392/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.6871e-06 - val_loss: 9.3683e-06\n",
      "Epoch 393/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.6987e-06 - val_loss: 9.2821e-06\n",
      "Epoch 394/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.6009e-06 - val_loss: 8.7184e-06\n",
      "Epoch 395/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.6841e-06 - val_loss: 8.6865e-06\n",
      "Epoch 396/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.6827e-06 - val_loss: 9.7669e-06\n",
      "Epoch 397/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.6028e-06 - val_loss: 8.9696e-06\n",
      "Epoch 398/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.6079e-06 - val_loss: 9.0036e-06\n",
      "Epoch 399/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.7066e-06 - val_loss: 8.4986e-06\n",
      "Epoch 400/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.6133e-06 - val_loss: 9.9924e-06\n",
      "Epoch 401/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.5768e-06 - val_loss: 8.9263e-06\n",
      "Epoch 402/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.5869e-06 - val_loss: 8.6693e-06\n",
      "Epoch 403/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.5381e-06 - val_loss: 8.9278e-06\n",
      "Epoch 404/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.6082e-06 - val_loss: 9.2220e-06\n",
      "Epoch 405/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.6186e-06 - val_loss: 8.5857e-06\n",
      "Epoch 406/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.5897e-06 - val_loss: 8.9189e-06\n",
      "Epoch 407/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.5373e-06 - val_loss: 8.4922e-06\n",
      "Epoch 408/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.5136e-06 - val_loss: 8.2661e-06\n",
      "Epoch 409/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.5599e-06 - val_loss: 9.8870e-06\n",
      "Epoch 410/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.4888e-06 - val_loss: 8.8987e-06\n",
      "Epoch 411/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.5203e-06 - val_loss: 9.1511e-06\n",
      "Epoch 412/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.5570e-06 - val_loss: 9.3212e-06\n",
      "Epoch 413/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.4572e-06 - val_loss: 9.2354e-06\n",
      "Epoch 414/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.4934e-06 - val_loss: 8.6379e-06\n",
      "Epoch 415/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.4937e-06 - val_loss: 8.8887e-06\n",
      "Epoch 416/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.5029e-06 - val_loss: 8.3683e-06\n",
      "Epoch 417/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.3994e-06 - val_loss: 9.1475e-06\n",
      "Epoch 418/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.4789e-06 - val_loss: 9.3691e-06\n",
      "Epoch 419/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.4434e-06 - val_loss: 8.4419e-06\n",
      "Epoch 420/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.3686e-06 - val_loss: 9.1333e-06\n",
      "Epoch 421/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.4900e-06 - val_loss: 8.4125e-06\n",
      "Epoch 422/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.4509e-06 - val_loss: 8.9188e-06\n",
      "Epoch 423/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.3879e-06 - val_loss: 9.4570e-06\n",
      "Epoch 424/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.4339e-06 - val_loss: 8.1253e-06\n",
      "Epoch 425/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.3701e-06 - val_loss: 8.3956e-06\n",
      "Epoch 426/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.3725e-06 - val_loss: 9.0616e-06\n",
      "Epoch 427/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.4259e-06 - val_loss: 9.1886e-06\n",
      "Epoch 428/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.3260e-06 - val_loss: 8.6953e-06\n",
      "Epoch 429/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.3703e-06 - val_loss: 8.8804e-06\n",
      "Epoch 430/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.3411e-06 - val_loss: 8.2746e-06\n",
      "Epoch 431/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.4021e-06 - val_loss: 9.0438e-06\n",
      "Epoch 432/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.2448e-06 - val_loss: 8.5014e-06\n",
      "Epoch 433/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 7s 13ms/step - loss: 8.3320e-06 - val_loss: 8.2485e-06\n",
      "Epoch 434/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.2742e-06 - val_loss: 8.7824e-06\n",
      "Epoch 435/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.2566e-06 - val_loss: 9.2687e-06\n",
      "Epoch 436/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.3008e-06 - val_loss: 9.2204e-06\n",
      "Epoch 437/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.2813e-06 - val_loss: 8.6802e-06\n",
      "Epoch 438/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.3180e-06 - val_loss: 9.2281e-06\n",
      "Epoch 439/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.2934e-06 - val_loss: 1.0286e-05\n",
      "Epoch 440/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.2609e-06 - val_loss: 8.2805e-06\n",
      "Epoch 441/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.1786e-06 - val_loss: 8.3108e-06\n",
      "Epoch 442/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.2485e-06 - val_loss: 9.1701e-06\n",
      "Epoch 443/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.2671e-06 - val_loss: 9.7318e-06\n",
      "Epoch 444/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.2175e-06 - val_loss: 9.8035e-06\n",
      "Epoch 445/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.1624e-06 - val_loss: 8.1801e-06\n",
      "Epoch 446/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.1619e-06 - val_loss: 8.2250e-06\n",
      "Epoch 447/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.2511e-06 - val_loss: 8.8626e-06\n",
      "Epoch 448/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.2034e-06 - val_loss: 8.4813e-06\n",
      "Epoch 449/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.2271e-06 - val_loss: 8.3037e-06\n",
      "Epoch 450/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.1533e-06 - val_loss: 8.2663e-06\n",
      "Epoch 451/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.1309e-06 - val_loss: 7.9040e-06\n",
      "Epoch 452/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.1523e-06 - val_loss: 8.8426e-06\n",
      "Epoch 453/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.0735e-06 - val_loss: 8.1542e-06\n",
      "Epoch 454/1000\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 8.1494e-06 - val_loss: 8.9636e-06\n",
      "Epoch 455/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.1317e-06 - val_loss: 8.4991e-06\n",
      "Epoch 456/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.1253e-06 - val_loss: 8.0990e-06\n",
      "Epoch 457/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.1073e-06 - val_loss: 8.7557e-06\n",
      "Epoch 458/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.0598e-06 - val_loss: 9.7562e-06\n",
      "Epoch 459/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.0623e-06 - val_loss: 8.9155e-06\n",
      "Epoch 460/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.0280e-06 - val_loss: 8.2276e-06\n",
      "Epoch 461/1000\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 8.0913e-06 - val_loss: 8.4840e-06\n",
      "Epoch 462/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.0917e-06 - val_loss: 8.0319e-06\n",
      "Epoch 463/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.9969e-06 - val_loss: 7.8489e-06\n",
      "Epoch 464/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.0589e-06 - val_loss: 8.2864e-06\n",
      "Epoch 465/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.0315e-06 - val_loss: 8.2856e-06\n",
      "Epoch 466/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.0161e-06 - val_loss: 8.1619e-06\n",
      "Epoch 467/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.9694e-06 - val_loss: 9.1553e-06\n",
      "Epoch 468/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.9918e-06 - val_loss: 8.4809e-06\n",
      "Epoch 469/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.0679e-06 - val_loss: 8.2224e-06\n",
      "Epoch 470/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.9988e-06 - val_loss: 8.0879e-06\n",
      "Epoch 471/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.0149e-06 - val_loss: 8.3532e-06\n",
      "Epoch 472/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.9562e-06 - val_loss: 8.4467e-06\n",
      "Epoch 473/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.0325e-06 - val_loss: 8.3874e-06\n",
      "Epoch 474/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.9480e-06 - val_loss: 9.5318e-06\n",
      "Epoch 475/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.9693e-06 - val_loss: 8.3149e-06\n",
      "Epoch 476/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.9590e-06 - val_loss: 8.6674e-06\n",
      "Epoch 477/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.0163e-06 - val_loss: 8.5935e-06\n",
      "Epoch 478/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.9101e-06 - val_loss: 9.2581e-06\n",
      "Epoch 479/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 8.0006e-06 - val_loss: 8.1823e-06\n",
      "Epoch 480/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.8794e-06 - val_loss: 8.5892e-06\n",
      "Epoch 481/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.9102e-06 - val_loss: 8.6819e-06\n",
      "Epoch 482/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.9752e-06 - val_loss: 9.2385e-06\n",
      "Epoch 483/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.8681e-06 - val_loss: 8.1103e-06\n",
      "Epoch 484/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.7931e-06 - val_loss: 8.7939e-06\n",
      "Epoch 485/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.9549e-06 - val_loss: 8.8804e-06\n",
      "Epoch 486/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.8895e-06 - val_loss: 8.8802e-06\n",
      "Epoch 487/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.8637e-06 - val_loss: 7.8730e-06\n",
      "Epoch 488/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.8367e-06 - val_loss: 8.6041e-06\n",
      "Epoch 489/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.8454e-06 - val_loss: 7.8972e-06\n",
      "Epoch 490/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.8395e-06 - val_loss: 7.6912e-06\n",
      "Epoch 491/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.8655e-06 - val_loss: 1.0105e-05\n",
      "Epoch 492/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.7985e-06 - val_loss: 8.3711e-06\n",
      "Epoch 493/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.7820e-06 - val_loss: 7.6527e-06\n",
      "Epoch 494/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.8208e-06 - val_loss: 8.9018e-06\n",
      "Epoch 495/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.8322e-06 - val_loss: 8.3213e-06\n",
      "Epoch 496/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.7794e-06 - val_loss: 8.5218e-06\n",
      "Epoch 497/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.8011e-06 - val_loss: 8.9209e-06\n",
      "Epoch 498/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.8000e-06 - val_loss: 8.7398e-06\n",
      "Epoch 499/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.7770e-06 - val_loss: 8.9076e-06\n",
      "Epoch 500/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.7895e-06 - val_loss: 9.9937e-06\n",
      "Epoch 501/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.7768e-06 - val_loss: 7.5943e-06\n",
      "Epoch 502/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.7209e-06 - val_loss: 7.9851e-06\n",
      "Epoch 503/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.7277e-06 - val_loss: 7.7864e-06\n",
      "Epoch 504/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.8284e-06 - val_loss: 7.8058e-06\n",
      "Epoch 505/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 7s 13ms/step - loss: 7.7565e-06 - val_loss: 9.3367e-06\n",
      "Epoch 506/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.7720e-06 - val_loss: 9.1768e-06\n",
      "Epoch 507/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.6663e-06 - val_loss: 8.7801e-06\n",
      "Epoch 508/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.6804e-06 - val_loss: 8.8128e-06\n",
      "Epoch 509/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.6954e-06 - val_loss: 7.8360e-06\n",
      "Epoch 510/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.7303e-06 - val_loss: 7.9489e-06\n",
      "Epoch 511/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.6265e-06 - val_loss: 8.1507e-06\n",
      "Epoch 512/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.7016e-06 - val_loss: 7.6909e-06\n",
      "Epoch 513/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.6731e-06 - val_loss: 8.4975e-06\n",
      "Epoch 514/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.7328e-06 - val_loss: 8.0787e-06\n",
      "Epoch 515/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.7523e-06 - val_loss: 7.9337e-06\n",
      "Epoch 516/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.6358e-06 - val_loss: 8.4613e-06\n",
      "Epoch 517/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.5950e-06 - val_loss: 8.1011e-06\n",
      "Epoch 518/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.6758e-06 - val_loss: 7.6906e-06\n",
      "Epoch 519/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.6463e-06 - val_loss: 8.3026e-06\n",
      "Epoch 520/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.6611e-06 - val_loss: 7.7971e-06\n",
      "Epoch 521/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.6091e-06 - val_loss: 8.6680e-06\n",
      "Epoch 522/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.6338e-06 - val_loss: 7.4541e-06\n",
      "Epoch 523/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.5805e-06 - val_loss: 7.7759e-06\n",
      "Epoch 524/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.6159e-06 - val_loss: 8.8914e-06\n",
      "Epoch 525/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.5923e-06 - val_loss: 9.4867e-06\n",
      "Epoch 526/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.5527e-06 - val_loss: 8.2691e-06\n",
      "Epoch 527/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.5912e-06 - val_loss: 8.1886e-06\n",
      "Epoch 528/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.6285e-06 - val_loss: 8.1095e-06\n",
      "Epoch 529/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.6106e-06 - val_loss: 7.7657e-06\n",
      "Epoch 530/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.5799e-06 - val_loss: 7.9504e-06\n",
      "Epoch 531/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.5577e-06 - val_loss: 8.0233e-06\n",
      "Epoch 532/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.5686e-06 - val_loss: 7.3497e-06\n",
      "Epoch 533/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.5083e-06 - val_loss: 8.0118e-06\n",
      "Epoch 534/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.5993e-06 - val_loss: 7.1930e-06\n",
      "Epoch 535/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.5979e-06 - val_loss: 8.1735e-06\n",
      "Epoch 536/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4990e-06 - val_loss: 8.6511e-06\n",
      "Epoch 537/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.5074e-06 - val_loss: 7.8756e-06\n",
      "Epoch 538/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4842e-06 - val_loss: 8.6924e-06\n",
      "Epoch 539/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.5278e-06 - val_loss: 7.5252e-06\n",
      "Epoch 540/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4290e-06 - val_loss: 8.7138e-06\n",
      "Epoch 541/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4678e-06 - val_loss: 7.9192e-06\n",
      "Epoch 542/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.5000e-06 - val_loss: 8.9157e-06\n",
      "Epoch 543/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.5052e-06 - val_loss: 8.7561e-06\n",
      "Epoch 544/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4719e-06 - val_loss: 7.5604e-06\n",
      "Epoch 545/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4679e-06 - val_loss: 8.7496e-06\n",
      "Epoch 546/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4594e-06 - val_loss: 8.5314e-06\n",
      "Epoch 547/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4625e-06 - val_loss: 8.1632e-06\n",
      "Epoch 548/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4763e-06 - val_loss: 8.0801e-06\n",
      "Epoch 549/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4369e-06 - val_loss: 8.2105e-06\n",
      "Epoch 550/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4259e-06 - val_loss: 8.1826e-06\n",
      "Epoch 551/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4292e-06 - val_loss: 7.6046e-06\n",
      "Epoch 552/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4512e-06 - val_loss: 7.6981e-06\n",
      "Epoch 553/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4017e-06 - val_loss: 7.8503e-06\n",
      "Epoch 554/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4252e-06 - val_loss: 8.4093e-06\n",
      "Epoch 555/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4181e-06 - val_loss: 7.4291e-06\n",
      "Epoch 556/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4078e-06 - val_loss: 7.9712e-06\n",
      "Epoch 557/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.3653e-06 - val_loss: 7.8954e-06\n",
      "Epoch 558/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4106e-06 - val_loss: 8.2176e-06\n",
      "Epoch 559/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.3840e-06 - val_loss: 7.8437e-06\n",
      "Epoch 560/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.4039e-06 - val_loss: 8.0263e-06\n",
      "Epoch 561/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.3368e-06 - val_loss: 7.6758e-06\n",
      "Epoch 562/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2909e-06 - val_loss: 7.2783e-06\n",
      "Epoch 563/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.3516e-06 - val_loss: 7.6729e-06\n",
      "Epoch 564/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.3035e-06 - val_loss: 7.9368e-06\n",
      "Epoch 565/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.3104e-06 - val_loss: 7.7360e-06\n",
      "Epoch 566/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.3062e-06 - val_loss: 8.0914e-06\n",
      "Epoch 567/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2675e-06 - val_loss: 7.9161e-06\n",
      "Epoch 568/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2679e-06 - val_loss: 7.5530e-06\n",
      "Epoch 569/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.3200e-06 - val_loss: 7.8450e-06\n",
      "Epoch 570/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.3329e-06 - val_loss: 8.3283e-06\n",
      "Epoch 571/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2316e-06 - val_loss: 7.1590e-06\n",
      "Epoch 572/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2784e-06 - val_loss: 7.0927e-06\n",
      "Epoch 573/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2631e-06 - val_loss: 7.2407e-06\n",
      "Epoch 574/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2123e-06 - val_loss: 7.2570e-06\n",
      "Epoch 575/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2601e-06 - val_loss: 7.5000e-06\n",
      "Epoch 576/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.3330e-06 - val_loss: 7.6589e-06\n",
      "Epoch 577/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2270e-06 - val_loss: 8.3133e-06\n",
      "Epoch 578/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2657e-06 - val_loss: 7.8284e-06\n",
      "Epoch 579/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2500e-06 - val_loss: 7.2623e-06\n",
      "Epoch 580/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2291e-06 - val_loss: 7.1954e-06\n",
      "Epoch 581/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1755e-06 - val_loss: 7.5821e-06\n",
      "Epoch 582/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2485e-06 - val_loss: 7.8706e-06\n",
      "Epoch 583/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1751e-06 - val_loss: 7.2468e-06\n",
      "Epoch 584/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2229e-06 - val_loss: 7.7001e-06\n",
      "Epoch 585/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1903e-06 - val_loss: 7.9373e-06\n",
      "Epoch 586/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1655e-06 - val_loss: 7.4855e-06\n",
      "Epoch 587/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2457e-06 - val_loss: 8.1690e-06\n",
      "Epoch 588/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.2550e-06 - val_loss: 7.2569e-06\n",
      "Epoch 589/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1758e-06 - val_loss: 7.5758e-06\n",
      "Epoch 590/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0763e-06 - val_loss: 7.6974e-06\n",
      "Epoch 591/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1949e-06 - val_loss: 8.2279e-06\n",
      "Epoch 592/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1638e-06 - val_loss: 7.1797e-06\n",
      "Epoch 593/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0816e-06 - val_loss: 7.4252e-06\n",
      "Epoch 594/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1968e-06 - val_loss: 7.5294e-06\n",
      "Epoch 595/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1778e-06 - val_loss: 7.4236e-06\n",
      "Epoch 596/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1480e-06 - val_loss: 7.0877e-06\n",
      "Epoch 597/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1112e-06 - val_loss: 7.6370e-06\n",
      "Epoch 598/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1363e-06 - val_loss: 7.4445e-06\n",
      "Epoch 599/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1395e-06 - val_loss: 7.1620e-06\n",
      "Epoch 600/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1197e-06 - val_loss: 7.1056e-06\n",
      "Epoch 601/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1473e-06 - val_loss: 7.4264e-06\n",
      "Epoch 602/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0664e-06 - val_loss: 7.7483e-06\n",
      "Epoch 603/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1132e-06 - val_loss: 8.1887e-06\n",
      "Epoch 604/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0966e-06 - val_loss: 8.0506e-06\n",
      "Epoch 605/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1057e-06 - val_loss: 7.6553e-06\n",
      "Epoch 606/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1498e-06 - val_loss: 7.8863e-06\n",
      "Epoch 607/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0597e-06 - val_loss: 7.5223e-06\n",
      "Epoch 608/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0434e-06 - val_loss: 7.2423e-06\n",
      "Epoch 609/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1192e-06 - val_loss: 7.0999e-06\n",
      "Epoch 610/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0454e-06 - val_loss: 7.5317e-06\n",
      "Epoch 611/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1073e-06 - val_loss: 7.7771e-06\n",
      "Epoch 612/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.1127e-06 - val_loss: 7.4447e-06\n",
      "Epoch 613/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0639e-06 - val_loss: 7.9902e-06\n",
      "Epoch 614/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0389e-06 - val_loss: 7.6586e-06\n",
      "Epoch 615/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0324e-06 - val_loss: 7.5974e-06\n",
      "Epoch 616/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0686e-06 - val_loss: 7.7088e-06\n",
      "Epoch 617/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9837e-06 - val_loss: 7.2835e-06\n",
      "Epoch 618/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0239e-06 - val_loss: 7.0555e-06\n",
      "Epoch 619/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9810e-06 - val_loss: 7.3284e-06\n",
      "Epoch 620/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0381e-06 - val_loss: 7.0926e-06\n",
      "Epoch 621/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0193e-06 - val_loss: 7.8101e-06\n",
      "Epoch 622/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9808e-06 - val_loss: 7.4684e-06\n",
      "Epoch 623/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0449e-06 - val_loss: 7.2108e-06\n",
      "Epoch 624/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9659e-06 - val_loss: 7.2457e-06\n",
      "Epoch 625/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0306e-06 - val_loss: 8.2778e-06\n",
      "Epoch 626/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9633e-06 - val_loss: 8.8906e-06\n",
      "Epoch 627/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0210e-06 - val_loss: 7.2613e-06\n",
      "Epoch 628/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9248e-06 - val_loss: 6.9211e-06\n",
      "Epoch 629/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9494e-06 - val_loss: 6.9094e-06\n",
      "Epoch 630/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0036e-06 - val_loss: 7.7185e-06\n",
      "Epoch 631/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9893e-06 - val_loss: 8.0257e-06\n",
      "Epoch 632/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9919e-06 - val_loss: 8.2024e-06\n",
      "Epoch 633/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9855e-06 - val_loss: 7.6314e-06\n",
      "Epoch 634/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 7.0052e-06 - val_loss: 7.3538e-06\n",
      "Epoch 635/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9698e-06 - val_loss: 7.5436e-06\n",
      "Epoch 636/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9390e-06 - val_loss: 7.4442e-06\n",
      "Epoch 637/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9511e-06 - val_loss: 7.3209e-06\n",
      "Epoch 638/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9396e-06 - val_loss: 7.2479e-06\n",
      "Epoch 639/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9181e-06 - val_loss: 7.4512e-06\n",
      "Epoch 640/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9546e-06 - val_loss: 7.1133e-06\n",
      "Epoch 641/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9443e-06 - val_loss: 7.0778e-06\n",
      "Epoch 642/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9343e-06 - val_loss: 7.2228e-06\n",
      "Epoch 643/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8269e-06 - val_loss: 7.5768e-06\n",
      "Epoch 644/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8968e-06 - val_loss: 7.5278e-06\n",
      "Epoch 645/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9690e-06 - val_loss: 7.5276e-06\n",
      "Epoch 646/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8660e-06 - val_loss: 8.2470e-06\n",
      "Epoch 647/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9367e-06 - val_loss: 7.5509e-06\n",
      "Epoch 648/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9405e-06 - val_loss: 7.1453e-06\n",
      "Epoch 649/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8019e-06 - val_loss: 7.2727e-06\n",
      "Epoch 650/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9142e-06 - val_loss: 7.2066e-06\n",
      "Epoch 651/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8736e-06 - val_loss: 7.1138e-06\n",
      "Epoch 652/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8630e-06 - val_loss: 7.6689e-06\n",
      "Epoch 653/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8654e-06 - val_loss: 8.1733e-06\n",
      "Epoch 654/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8355e-06 - val_loss: 7.6114e-06\n",
      "Epoch 655/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8594e-06 - val_loss: 7.6157e-06\n",
      "Epoch 656/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.9202e-06 - val_loss: 7.5443e-06\n",
      "Epoch 657/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8609e-06 - val_loss: 7.5206e-06\n",
      "Epoch 658/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8128e-06 - val_loss: 6.9762e-06\n",
      "Epoch 659/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8256e-06 - val_loss: 7.3563e-06\n",
      "Epoch 660/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8099e-06 - val_loss: 7.3484e-06\n",
      "Epoch 661/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8069e-06 - val_loss: 7.3005e-06\n",
      "Epoch 662/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8367e-06 - val_loss: 7.4506e-06\n",
      "Epoch 663/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8135e-06 - val_loss: 6.9377e-06\n",
      "Epoch 664/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7938e-06 - val_loss: 6.8557e-06\n",
      "Epoch 665/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8262e-06 - val_loss: 7.3038e-06\n",
      "Epoch 666/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7824e-06 - val_loss: 7.5872e-06\n",
      "Epoch 667/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8421e-06 - val_loss: 7.0960e-06\n",
      "Epoch 668/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7801e-06 - val_loss: 6.9263e-06\n",
      "Epoch 669/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7547e-06 - val_loss: 7.0564e-06\n",
      "Epoch 670/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8061e-06 - val_loss: 7.0513e-06\n",
      "Epoch 671/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7580e-06 - val_loss: 6.8692e-06\n",
      "Epoch 672/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8014e-06 - val_loss: 8.0458e-06\n",
      "Epoch 673/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7864e-06 - val_loss: 6.8327e-06\n",
      "Epoch 674/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8414e-06 - val_loss: 8.0219e-06\n",
      "Epoch 675/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7499e-06 - val_loss: 6.9602e-06\n",
      "Epoch 676/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7568e-06 - val_loss: 6.8893e-06\n",
      "Epoch 677/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7661e-06 - val_loss: 7.1019e-06\n",
      "Epoch 678/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7692e-06 - val_loss: 7.3341e-06\n",
      "Epoch 679/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7518e-06 - val_loss: 6.9430e-06\n",
      "Epoch 680/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7725e-06 - val_loss: 7.6875e-06\n",
      "Epoch 681/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7379e-06 - val_loss: 6.9440e-06\n",
      "Epoch 682/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.8145e-06 - val_loss: 7.3596e-06\n",
      "Epoch 683/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7673e-06 - val_loss: 7.2117e-06\n",
      "Epoch 684/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7864e-06 - val_loss: 6.5973e-06\n",
      "Epoch 685/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6356e-06 - val_loss: 7.1074e-06\n",
      "Epoch 686/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7856e-06 - val_loss: 7.7501e-06\n",
      "Epoch 687/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7620e-06 - val_loss: 7.0228e-06\n",
      "Epoch 688/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7748e-06 - val_loss: 8.0677e-06\n",
      "Epoch 689/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6653e-06 - val_loss: 6.9586e-06\n",
      "Epoch 690/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7088e-06 - val_loss: 7.2583e-06\n",
      "Epoch 691/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7323e-06 - val_loss: 7.3216e-06\n",
      "Epoch 692/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6897e-06 - val_loss: 6.6983e-06\n",
      "Epoch 693/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6922e-06 - val_loss: 7.1835e-06\n",
      "Epoch 694/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6608e-06 - val_loss: 7.0146e-06\n",
      "Epoch 695/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6722e-06 - val_loss: 7.0662e-06\n",
      "Epoch 696/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7346e-06 - val_loss: 6.8686e-06\n",
      "Epoch 697/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.7014e-06 - val_loss: 6.9479e-06\n",
      "Epoch 698/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6844e-06 - val_loss: 7.1475e-06\n",
      "Epoch 699/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6904e-06 - val_loss: 6.7871e-06\n",
      "Epoch 700/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6892e-06 - val_loss: 6.8820e-06\n",
      "Epoch 701/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6835e-06 - val_loss: 7.2281e-06\n",
      "Epoch 702/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6194e-06 - val_loss: 7.3579e-06\n",
      "Epoch 703/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6653e-06 - val_loss: 6.7812e-06\n",
      "Epoch 704/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6446e-06 - val_loss: 6.9916e-06\n",
      "Epoch 705/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6483e-06 - val_loss: 7.1414e-06\n",
      "Epoch 706/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6062e-06 - val_loss: 7.1040e-06\n",
      "Epoch 707/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6476e-06 - val_loss: 6.8430e-06\n",
      "Epoch 708/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6507e-06 - val_loss: 6.6637e-06\n",
      "Epoch 709/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6275e-06 - val_loss: 6.9871e-06\n",
      "Epoch 710/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5932e-06 - val_loss: 7.3903e-06\n",
      "Epoch 711/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6268e-06 - val_loss: 6.6905e-06\n",
      "Epoch 712/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6338e-06 - val_loss: 7.1014e-06\n",
      "Epoch 713/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5752e-06 - val_loss: 6.6007e-06\n",
      "Epoch 714/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5845e-06 - val_loss: 7.5435e-06\n",
      "Epoch 715/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6749e-06 - val_loss: 6.8575e-06\n",
      "Epoch 716/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6309e-06 - val_loss: 7.1923e-06\n",
      "Epoch 717/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6302e-06 - val_loss: 7.2489e-06\n",
      "Epoch 718/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5992e-06 - val_loss: 6.4400e-06\n",
      "Epoch 719/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6604e-06 - val_loss: 6.8232e-06\n",
      "Epoch 720/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5596e-06 - val_loss: 7.4397e-06\n",
      "Epoch 721/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6383e-06 - val_loss: 6.7683e-06\n",
      "Epoch 722/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5840e-06 - val_loss: 7.1318e-06\n",
      "Epoch 723/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6175e-06 - val_loss: 7.7508e-06\n",
      "Epoch 724/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5741e-06 - val_loss: 6.7883e-06\n",
      "Epoch 725/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6148e-06 - val_loss: 7.7683e-06\n",
      "Epoch 726/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5906e-06 - val_loss: 8.5661e-06\n",
      "Epoch 727/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6187e-06 - val_loss: 7.0141e-06\n",
      "Epoch 728/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5406e-06 - val_loss: 6.6025e-06\n",
      "Epoch 729/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5953e-06 - val_loss: 7.1958e-06\n",
      "Epoch 730/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5672e-06 - val_loss: 6.7667e-06\n",
      "Epoch 731/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6109e-06 - val_loss: 7.3931e-06\n",
      "Epoch 732/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5734e-06 - val_loss: 7.4319e-06\n",
      "Epoch 733/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.6181e-06 - val_loss: 7.0914e-06\n",
      "Epoch 734/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5344e-06 - val_loss: 7.4585e-06\n",
      "Epoch 735/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5328e-06 - val_loss: 6.7060e-06\n",
      "Epoch 736/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5433e-06 - val_loss: 6.4508e-06\n",
      "Epoch 737/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5845e-06 - val_loss: 8.5103e-06\n",
      "Epoch 738/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5366e-06 - val_loss: 7.1674e-06\n",
      "Epoch 739/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5420e-06 - val_loss: 6.8666e-06\n",
      "Epoch 740/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5612e-06 - val_loss: 7.2844e-06\n",
      "Epoch 741/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5805e-06 - val_loss: 7.3762e-06\n",
      "Epoch 742/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5521e-06 - val_loss: 6.4625e-06\n",
      "Epoch 743/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5313e-06 - val_loss: 9.0250e-06\n",
      "Epoch 744/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5646e-06 - val_loss: 7.9557e-06\n",
      "Epoch 745/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4527e-06 - val_loss: 7.1931e-06\n",
      "Epoch 746/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4899e-06 - val_loss: 6.7456e-06\n",
      "Epoch 747/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4455e-06 - val_loss: 7.0048e-06\n",
      "Epoch 748/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4963e-06 - val_loss: 7.2617e-06\n",
      "Epoch 749/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5046e-06 - val_loss: 6.6036e-06\n",
      "Epoch 750/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4859e-06 - val_loss: 6.8588e-06\n",
      "Epoch 751/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5335e-06 - val_loss: 7.0916e-06\n",
      "Epoch 752/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4884e-06 - val_loss: 6.8231e-06\n",
      "Epoch 753/1000\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 6.4633e-06 - val_loss: 7.6397e-06\n",
      "Epoch 754/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5095e-06 - val_loss: 7.5026e-06\n",
      "Epoch 755/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5284e-06 - val_loss: 6.4116e-06\n",
      "Epoch 756/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4960e-06 - val_loss: 6.7175e-06\n",
      "Epoch 757/1000\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 6.4809e-06 - val_loss: 6.5372e-06\n",
      "Epoch 758/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4870e-06 - val_loss: 7.0958e-06\n",
      "Epoch 759/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5059e-06 - val_loss: 6.5837e-06\n",
      "Epoch 760/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4801e-06 - val_loss: 6.9557e-06\n",
      "Epoch 761/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5093e-06 - val_loss: 7.7952e-06\n",
      "Epoch 762/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4284e-06 - val_loss: 6.5629e-06\n",
      "Epoch 763/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4943e-06 - val_loss: 6.6470e-06\n",
      "Epoch 764/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4585e-06 - val_loss: 7.7919e-06\n",
      "Epoch 765/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4706e-06 - val_loss: 6.8675e-06\n",
      "Epoch 766/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4411e-06 - val_loss: 8.8979e-06\n",
      "Epoch 767/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4095e-06 - val_loss: 7.2734e-06\n",
      "Epoch 768/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4298e-06 - val_loss: 6.5902e-06\n",
      "Epoch 769/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.5656e-06 - val_loss: 6.5636e-06\n",
      "Epoch 770/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4324e-06 - val_loss: 6.9498e-06\n",
      "Epoch 771/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4362e-06 - val_loss: 7.4908e-06\n",
      "Epoch 772/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4047e-06 - val_loss: 6.7428e-06\n",
      "Epoch 773/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4794e-06 - val_loss: 6.5392e-06\n",
      "Epoch 774/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3969e-06 - val_loss: 7.0541e-06\n",
      "Epoch 775/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3892e-06 - val_loss: 7.0100e-06\n",
      "Epoch 776/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4194e-06 - val_loss: 6.8184e-06\n",
      "Epoch 777/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4688e-06 - val_loss: 6.8868e-06\n",
      "Epoch 778/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4345e-06 - val_loss: 6.7891e-06\n",
      "Epoch 779/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4499e-06 - val_loss: 7.6641e-06\n",
      "Epoch 780/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4317e-06 - val_loss: 7.3130e-06\n",
      "Epoch 781/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4327e-06 - val_loss: 7.4939e-06\n",
      "Epoch 782/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4519e-06 - val_loss: 6.2978e-06\n",
      "Epoch 783/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3618e-06 - val_loss: 6.3453e-06\n",
      "Epoch 784/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4023e-06 - val_loss: 6.9323e-06\n",
      "Epoch 785/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4066e-06 - val_loss: 7.2746e-06\n",
      "Epoch 786/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3784e-06 - val_loss: 7.3199e-06\n",
      "Epoch 787/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3661e-06 - val_loss: 6.7270e-06\n",
      "Epoch 788/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3816e-06 - val_loss: 7.3572e-06\n",
      "Epoch 789/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4017e-06 - val_loss: 7.6317e-06\n",
      "Epoch 790/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3674e-06 - val_loss: 6.8696e-06\n",
      "Epoch 791/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3955e-06 - val_loss: 7.6615e-06\n",
      "Epoch 792/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3878e-06 - val_loss: 6.6213e-06\n",
      "Epoch 793/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3482e-06 - val_loss: 7.1144e-06\n",
      "Epoch 794/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4424e-06 - val_loss: 6.8403e-06\n",
      "Epoch 795/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3595e-06 - val_loss: 7.0196e-06\n",
      "Epoch 796/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3030e-06 - val_loss: 7.1557e-06\n",
      "Epoch 797/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.4350e-06 - val_loss: 6.3440e-06\n",
      "Epoch 798/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3635e-06 - val_loss: 6.7205e-06\n",
      "Epoch 799/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3399e-06 - val_loss: 6.9217e-06\n",
      "Epoch 800/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3740e-06 - val_loss: 6.8672e-06\n",
      "Epoch 801/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3427e-06 - val_loss: 7.4660e-06\n",
      "Epoch 802/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3805e-06 - val_loss: 6.8886e-06\n",
      "Epoch 803/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3484e-06 - val_loss: 6.4915e-06\n",
      "Epoch 804/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3062e-06 - val_loss: 7.1948e-06\n",
      "Epoch 805/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3528e-06 - val_loss: 8.8773e-06\n",
      "Epoch 806/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3853e-06 - val_loss: 7.0239e-06\n",
      "Epoch 807/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3843e-06 - val_loss: 6.4530e-06\n",
      "Epoch 808/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3347e-06 - val_loss: 7.0473e-06\n",
      "Epoch 809/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3229e-06 - val_loss: 6.3232e-06\n",
      "Epoch 810/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2795e-06 - val_loss: 6.8256e-06\n",
      "Epoch 811/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3601e-06 - val_loss: 6.5721e-06\n",
      "Epoch 812/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3778e-06 - val_loss: 7.2754e-06\n",
      "Epoch 813/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3088e-06 - val_loss: 6.4896e-06\n",
      "Epoch 814/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3544e-06 - val_loss: 7.4440e-06\n",
      "Epoch 815/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2851e-06 - val_loss: 7.2352e-06\n",
      "Epoch 816/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3441e-06 - val_loss: 6.9445e-06\n",
      "Epoch 817/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2529e-06 - val_loss: 6.5740e-06\n",
      "Epoch 818/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2978e-06 - val_loss: 7.6419e-06\n",
      "Epoch 819/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3205e-06 - val_loss: 7.7962e-06\n",
      "Epoch 820/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2663e-06 - val_loss: 6.1385e-06\n",
      "Epoch 821/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3157e-06 - val_loss: 7.0405e-06\n",
      "Epoch 822/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2894e-06 - val_loss: 7.0201e-06\n",
      "Epoch 823/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3447e-06 - val_loss: 6.8516e-06\n",
      "Epoch 824/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2723e-06 - val_loss: 7.2026e-06\n",
      "Epoch 825/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2461e-06 - val_loss: 6.9009e-06\n",
      "Epoch 826/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2637e-06 - val_loss: 6.6318e-06\n",
      "Epoch 827/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2683e-06 - val_loss: 6.0714e-06\n",
      "Epoch 828/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3345e-06 - val_loss: 6.8998e-06\n",
      "Epoch 829/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2665e-06 - val_loss: 6.9480e-06\n",
      "Epoch 830/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2530e-06 - val_loss: 7.0839e-06\n",
      "Epoch 831/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2757e-06 - val_loss: 6.8687e-06\n",
      "Epoch 832/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2082e-06 - val_loss: 6.3502e-06\n",
      "Epoch 833/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3299e-06 - val_loss: 6.7376e-06\n",
      "Epoch 834/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3116e-06 - val_loss: 6.7674e-06\n",
      "Epoch 835/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2505e-06 - val_loss: 7.1813e-06\n",
      "Epoch 836/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2871e-06 - val_loss: 6.7065e-06\n",
      "Epoch 837/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2678e-06 - val_loss: 6.6495e-06\n",
      "Epoch 838/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2663e-06 - val_loss: 6.4324e-06\n",
      "Epoch 839/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2584e-06 - val_loss: 6.4452e-06\n",
      "Epoch 840/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3246e-06 - val_loss: 6.4579e-06\n",
      "Epoch 841/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2795e-06 - val_loss: 6.3021e-06\n",
      "Epoch 842/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.3081e-06 - val_loss: 6.5985e-06\n",
      "Epoch 843/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2201e-06 - val_loss: 6.1876e-06\n",
      "Epoch 844/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2423e-06 - val_loss: 7.0295e-06\n",
      "Epoch 845/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1806e-06 - val_loss: 6.7547e-06\n",
      "Epoch 846/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2656e-06 - val_loss: 6.5358e-06\n",
      "Epoch 847/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2632e-06 - val_loss: 6.1647e-06\n",
      "Epoch 848/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2171e-06 - val_loss: 6.5310e-06\n",
      "Epoch 849/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2810e-06 - val_loss: 6.6865e-06\n",
      "Epoch 850/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1939e-06 - val_loss: 6.5070e-06\n",
      "Epoch 851/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2044e-06 - val_loss: 6.9753e-06\n",
      "Epoch 852/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1885e-06 - val_loss: 6.3930e-06\n",
      "Epoch 853/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2349e-06 - val_loss: 6.8528e-06\n",
      "Epoch 854/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2132e-06 - val_loss: 7.1265e-06\n",
      "Epoch 855/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2180e-06 - val_loss: 7.3123e-06\n",
      "Epoch 856/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2203e-06 - val_loss: 6.2823e-06\n",
      "Epoch 857/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1909e-06 - val_loss: 6.5683e-06\n",
      "Epoch 858/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1764e-06 - val_loss: 7.2190e-06\n",
      "Epoch 859/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2327e-06 - val_loss: 6.7619e-06\n",
      "Epoch 860/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2279e-06 - val_loss: 6.4787e-06\n",
      "Epoch 861/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1864e-06 - val_loss: 6.4521e-06\n",
      "Epoch 862/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2058e-06 - val_loss: 6.2398e-06\n",
      "Epoch 863/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1836e-06 - val_loss: 7.2289e-06\n",
      "Epoch 864/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1978e-06 - val_loss: 7.1997e-06\n",
      "Epoch 865/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1652e-06 - val_loss: 6.9643e-06\n",
      "Epoch 866/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1684e-06 - val_loss: 6.4344e-06\n",
      "Epoch 867/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1479e-06 - val_loss: 6.9656e-06\n",
      "Epoch 868/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1936e-06 - val_loss: 6.5238e-06\n",
      "Epoch 869/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2247e-06 - val_loss: 6.9702e-06\n",
      "Epoch 870/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1620e-06 - val_loss: 6.8571e-06\n",
      "Epoch 871/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1997e-06 - val_loss: 7.0343e-06\n",
      "Epoch 872/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2116e-06 - val_loss: 6.3221e-06\n",
      "Epoch 873/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1771e-06 - val_loss: 7.8348e-06\n",
      "Epoch 874/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1589e-06 - val_loss: 6.3569e-06\n",
      "Epoch 875/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1772e-06 - val_loss: 6.7140e-06\n",
      "Epoch 876/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1796e-06 - val_loss: 6.7276e-06\n",
      "Epoch 877/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1797e-06 - val_loss: 7.1795e-06\n",
      "Epoch 878/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2154e-06 - val_loss: 6.4171e-06\n",
      "Epoch 879/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1482e-06 - val_loss: 6.7080e-06\n",
      "Epoch 880/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1421e-06 - val_loss: 7.1201e-06\n",
      "Epoch 881/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1576e-06 - val_loss: 6.4847e-06\n",
      "Epoch 882/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0925e-06 - val_loss: 7.4081e-06\n",
      "Epoch 883/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1202e-06 - val_loss: 6.7737e-06\n",
      "Epoch 884/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.2210e-06 - val_loss: 6.4952e-06\n",
      "Epoch 885/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1249e-06 - val_loss: 6.8185e-06\n",
      "Epoch 886/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1293e-06 - val_loss: 6.6499e-06\n",
      "Epoch 887/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1367e-06 - val_loss: 6.9626e-06\n",
      "Epoch 888/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1145e-06 - val_loss: 6.6778e-06\n",
      "Epoch 889/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1022e-06 - val_loss: 7.0927e-06\n",
      "Epoch 890/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0879e-06 - val_loss: 6.6319e-06\n",
      "Epoch 891/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0870e-06 - val_loss: 6.9227e-06\n",
      "Epoch 892/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1459e-06 - val_loss: 6.5253e-06\n",
      "Epoch 893/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1418e-06 - val_loss: 6.9405e-06\n",
      "Epoch 894/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0800e-06 - val_loss: 7.0244e-06\n",
      "Epoch 895/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1201e-06 - val_loss: 7.2202e-06\n",
      "Epoch 896/1000\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 6.1078e-06 - val_loss: 6.5628e-06\n",
      "Epoch 897/1000\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 6.0949e-06 - val_loss: 6.7146e-06\n",
      "Epoch 898/1000\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 6.1352e-06 - val_loss: 7.6258e-06\n",
      "Epoch 899/1000\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 6.0457e-06 - val_loss: 6.3504e-06\n",
      "Epoch 900/1000\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 6.1254e-06 - val_loss: 6.1660e-06\n",
      "Epoch 901/1000\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 6.0717e-06 - val_loss: 5.9674e-06\n",
      "Epoch 902/1000\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 6.1131e-06 - val_loss: 6.7960e-06\n",
      "Epoch 903/1000\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 6.0835e-06 - val_loss: 6.6633e-06\n",
      "Epoch 904/1000\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 6.1236e-06 - val_loss: 6.0919e-06\n",
      "Epoch 905/1000\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 6.1024e-06 - val_loss: 7.2162e-06\n",
      "Epoch 906/1000\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 6.0847e-06 - val_loss: 6.3178e-06\n",
      "Epoch 907/1000\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 6.1503e-06 - val_loss: 6.5130e-06\n",
      "Epoch 908/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0667e-06 - val_loss: 6.3104e-06\n",
      "Epoch 909/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0676e-06 - val_loss: 7.2864e-06\n",
      "Epoch 910/1000\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 6.0087e-06 - val_loss: 6.4454e-06\n",
      "Epoch 911/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1124e-06 - val_loss: 6.4405e-06\n",
      "Epoch 912/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.1000e-06 - val_loss: 6.7110e-06\n",
      "Epoch 913/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0779e-06 - val_loss: 6.2979e-06\n",
      "Epoch 914/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0624e-06 - val_loss: 6.0967e-06\n",
      "Epoch 915/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0467e-06 - val_loss: 7.3787e-06\n",
      "Epoch 916/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0277e-06 - val_loss: 6.5045e-06\n",
      "Epoch 917/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0647e-06 - val_loss: 6.7444e-06\n",
      "Epoch 918/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0582e-06 - val_loss: 6.5262e-06\n",
      "Epoch 919/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0406e-06 - val_loss: 6.3505e-06\n",
      "Epoch 920/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9861e-06 - val_loss: 6.4608e-06\n",
      "Epoch 921/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0805e-06 - val_loss: 7.4583e-06\n",
      "Epoch 922/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0159e-06 - val_loss: 6.9164e-06\n",
      "Epoch 923/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0324e-06 - val_loss: 6.6841e-06\n",
      "Epoch 924/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0856e-06 - val_loss: 6.8267e-06\n",
      "Epoch 925/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0793e-06 - val_loss: 6.6143e-06\n",
      "Epoch 926/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0403e-06 - val_loss: 6.4980e-06\n",
      "Epoch 927/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0364e-06 - val_loss: 7.0857e-06\n",
      "Epoch 928/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0048e-06 - val_loss: 7.0959e-06\n",
      "Epoch 929/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0315e-06 - val_loss: 6.3770e-06\n",
      "Epoch 930/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0189e-06 - val_loss: 6.3340e-06\n",
      "Epoch 931/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0096e-06 - val_loss: 6.0350e-06\n",
      "Epoch 932/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0576e-06 - val_loss: 6.7473e-06\n",
      "Epoch 933/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9975e-06 - val_loss: 6.4062e-06\n",
      "Epoch 934/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0211e-06 - val_loss: 6.7044e-06\n",
      "Epoch 935/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0344e-06 - val_loss: 6.0287e-06\n",
      "Epoch 936/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9710e-06 - val_loss: 6.9151e-06\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0208e-06 - val_loss: 6.6003e-06\n",
      "Epoch 938/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9901e-06 - val_loss: 6.4600e-06\n",
      "Epoch 939/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0364e-06 - val_loss: 5.7279e-06\n",
      "Epoch 940/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9527e-06 - val_loss: 6.7455e-06\n",
      "Epoch 941/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0297e-06 - val_loss: 6.8641e-06\n",
      "Epoch 942/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0401e-06 - val_loss: 6.6616e-06\n",
      "Epoch 943/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9864e-06 - val_loss: 6.5170e-06\n",
      "Epoch 944/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9739e-06 - val_loss: 6.3421e-06\n",
      "Epoch 945/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9813e-06 - val_loss: 6.4832e-06\n",
      "Epoch 946/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0150e-06 - val_loss: 6.7092e-06\n",
      "Epoch 947/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9738e-06 - val_loss: 7.0929e-06\n",
      "Epoch 948/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9610e-06 - val_loss: 5.9394e-06\n",
      "Epoch 949/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9613e-06 - val_loss: 6.7793e-06\n",
      "Epoch 950/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0191e-06 - val_loss: 6.8141e-06\n",
      "Epoch 951/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9358e-06 - val_loss: 6.8207e-06\n",
      "Epoch 952/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9984e-06 - val_loss: 5.9707e-06\n",
      "Epoch 953/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9952e-06 - val_loss: 6.2678e-06\n",
      "Epoch 954/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9490e-06 - val_loss: 6.4250e-06\n",
      "Epoch 955/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9669e-06 - val_loss: 6.2954e-06\n",
      "Epoch 956/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9753e-06 - val_loss: 6.7723e-06\n",
      "Epoch 957/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9745e-06 - val_loss: 6.7834e-06\n",
      "Epoch 958/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9719e-06 - val_loss: 6.2058e-06\n",
      "Epoch 959/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.8929e-06 - val_loss: 6.3602e-06\n",
      "Epoch 960/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9487e-06 - val_loss: 6.3704e-06\n",
      "Epoch 961/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9913e-06 - val_loss: 6.4848e-06\n",
      "Epoch 962/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9318e-06 - val_loss: 6.3663e-06\n",
      "Epoch 963/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9653e-06 - val_loss: 6.9067e-06\n",
      "Epoch 964/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9488e-06 - val_loss: 6.0654e-06\n",
      "Epoch 965/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9730e-06 - val_loss: 5.7243e-06\n",
      "Epoch 966/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9099e-06 - val_loss: 7.1517e-06\n",
      "Epoch 967/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9796e-06 - val_loss: 5.9855e-06\n",
      "Epoch 968/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9785e-06 - val_loss: 5.9856e-06\n",
      "Epoch 969/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 6.0283e-06 - val_loss: 7.3865e-06\n",
      "Epoch 970/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9576e-06 - val_loss: 6.3592e-06\n",
      "Epoch 971/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9120e-06 - val_loss: 6.5078e-06\n",
      "Epoch 972/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9154e-06 - val_loss: 6.1037e-06\n",
      "Epoch 973/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.8645e-06 - val_loss: 6.1300e-06\n",
      "Epoch 974/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9491e-06 - val_loss: 6.4502e-06\n",
      "Epoch 975/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9409e-06 - val_loss: 6.4776e-06\n",
      "Epoch 976/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.8858e-06 - val_loss: 7.0555e-06\n",
      "Epoch 977/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9297e-06 - val_loss: 6.7650e-06\n",
      "Epoch 978/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9047e-06 - val_loss: 6.3112e-06\n",
      "Epoch 979/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9256e-06 - val_loss: 7.2382e-06\n",
      "Epoch 980/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9635e-06 - val_loss: 6.3002e-06\n",
      "Epoch 981/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.8737e-06 - val_loss: 5.9819e-06\n",
      "Epoch 982/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9349e-06 - val_loss: 6.0664e-06\n",
      "Epoch 983/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9422e-06 - val_loss: 6.2199e-06\n",
      "Epoch 984/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9231e-06 - val_loss: 6.4726e-06\n",
      "Epoch 985/1000\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.9015e-06 - val_loss: 7.1678e-06\n",
      "Epoch 986/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.8855e-06 - val_loss: 6.5717e-06\n",
      "Epoch 987/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9222e-06 - val_loss: 6.7635e-06\n",
      "Epoch 988/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.8999e-06 - val_loss: 6.7720e-06\n",
      "Epoch 989/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9714e-06 - val_loss: 7.0294e-06\n",
      "Epoch 990/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.8857e-06 - val_loss: 6.7206e-06\n",
      "Epoch 991/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.8459e-06 - val_loss: 5.8292e-06\n",
      "Epoch 992/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9419e-06 - val_loss: 6.6093e-06\n",
      "Epoch 993/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9042e-06 - val_loss: 6.5932e-06\n",
      "Epoch 994/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9030e-06 - val_loss: 6.8678e-06\n",
      "Epoch 995/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.8522e-06 - val_loss: 5.8695e-06\n",
      "Epoch 996/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.8950e-06 - val_loss: 6.6686e-06\n",
      "Epoch 997/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.8855e-06 - val_loss: 6.2596e-06\n",
      "Epoch 998/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.8686e-06 - val_loss: 6.9498e-06\n",
      "Epoch 999/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.8911e-06 - val_loss: 6.3082e-06\n",
      "Epoch 1000/1000\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 5.9055e-06 - val_loss: 6.1101e-06\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the specified params and save the train loss and val loss in a csv file\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=1000,\n",
    "                batch_size=200,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val, x_val),\n",
    "                callbacks=[history,\n",
    "                           TensorBoard(log_dir = path)])\n",
    "\n",
    "filename = 'files_06_channel/result/trainloss_%s.csv'%file\n",
    "loss_history = np.array(history.losses_train)\n",
    "np.savetxt(filename, loss_history, delimiter=\",\")\n",
    "\n",
    "filename = 'files_06_channel/result/valloss_%s.csv'%file\n",
    "loss_history = np.array(history.losses_val)\n",
    "np.savetxt(filename, loss_history, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3jnfm6hJ-zpt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 2s 3ms/step\n",
      "It cost 0.000127 sec\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "tStart = time.time()\n",
    "x_hat = autoencoder.predict(x_test)\n",
    "tEnd = time.time()\n",
    "print (\"It cost %f sec\" % ((tEnd - tStart)/x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mJcp8f_5--Zp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11145/1304209954.py:22: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  n1 = n1.astype('float64')\n",
      "/tmp/ipykernel_11145/1304209954.py:24: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  n2 = n2.astype('float64')\n"
     ]
    }
   ],
   "source": [
    "# Calcaulating the NMSE and rho\n",
    "if envir == 'indoor':\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_HtestFin_all.mat')\n",
    "  X_test = mat['HF_all']# array\n",
    "\n",
    "elif envir == 'outdoor':\n",
    "  mat = sio.loadmat('files_06_channel/data/DATA_HtestFout_all.mat')\n",
    "  X_test = mat['HF_all']# array\n",
    "\n",
    "X_test = np.reshape(X_test, (len(X_test), img_height, 125))\n",
    "x_test_real = np.reshape(x_test[:, 0, :, :], (len(x_test), -1))\n",
    "x_test_imag = np.reshape(x_test[:, 1, :, :], (len(x_test), -1))\n",
    "x_test_C = x_test_real-0.5 + 1j*(x_test_imag-0.5)\n",
    "x_hat_real = np.reshape(x_hat[:, 0, :, :], (len(x_hat), -1))\n",
    "x_hat_imag = np.reshape(x_hat[:, 1, :, :], (len(x_hat), -1))\n",
    "x_hat_C = x_hat_real-0.5 + 1j*(x_hat_imag-0.5)\n",
    "x_hat_F = np.reshape(x_hat_C, (len(x_hat_C), img_height, img_width))\n",
    "X_hat = np.fft.fft(np.concatenate((x_hat_F, np.zeros((len(x_hat_C), img_height, 257-img_width))), axis=2), axis=2)\n",
    "X_hat = X_hat[:, :, 0:125]\n",
    "\n",
    "n1 = np.sqrt(np.sum(np.conj(X_test)*X_test, axis=1))\n",
    "n1 = n1.astype('float64')\n",
    "n2 = np.sqrt(np.sum(np.conj(X_hat)*X_hat, axis=1))\n",
    "n2 = n2.astype('float64')\n",
    "aa = abs(np.sum(np.conj(X_test)*X_hat, axis=1))\n",
    "rho = np.mean(aa/(n1*n2), axis=1)\n",
    "X_hat = np.reshape(X_hat, (len(X_hat), -1))\n",
    "X_test = np.reshape(X_test, (len(X_test), -1))\n",
    "power = np.sum(abs(x_test_C)**2, axis=1)\n",
    "power_d = np.sum(abs(X_hat)**2, axis=1)\n",
    "mse = np.sum(abs(x_test_C-x_hat_C)**2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Y8k1F4iE_Pdw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In indoor environment\n",
      "When dimension is 512\n",
      "NMSE is  -18.631636873522087\n",
      "Correlation is  0.9902885986924393\n"
     ]
    }
   ],
   "source": [
    "print(\"In \"+envir+\" environment\")\n",
    "print(\"When dimension is\", encoded_dim)\n",
    "print(\"NMSE is \", 10*math.log10(np.mean(mse/power)))\n",
    "print(\"Correlation is \", np.mean(rho))\n",
    "\n",
    "filename = \"files_06_channel/result/decoded_%s.csv\"%file\n",
    "x_hat1 = np.reshape(x_hat, (len(x_hat), -1))\n",
    "np.savetxt(filename, x_hat1, delimiter=\",\")\n",
    "filename = \"files_06_channel/result/rho_%s.csv\"%file\n",
    "np.savetxt(filename, rho, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2p7tvVn7_WeS"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABiYAAAFECAYAAACjw4YIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAO0lEQVR4nO3dacxtV1kA4HXvLR1ue29pS6fb3raMMlUG00QTcfghQRsHBgVJRKIoSmOMAYz4B2MiIUqMJo5gMDEEo8E4xVmMiRMaRRBBKUWghQud2zu1vcP3+YOcw1nv2d9Ze5+z9zrT8/y6q+c7++zh3WutfVbP++7b3d3dTQAAAAAAABXsX/YOAAAAAAAA28PCBAAAAAAAUI2FCQAAAAAAoBoLEwAAAAAAQDUWJgAAAAAAgGosTAAAAAAAANVYmAAAAAAAAKqxMAEAAAAAAFRzwbxv3NnZSceOHUuHDh1K+/bt63OfWDO7u7vpxIkT6ciRI2n//uHWusQck8QdtdWKuZTEHV+hr2MZxB21GWNZBn0dyyDuqM0YyzK0jbu5FyaOHTuWjh49Ou/b2UD33HNPuvHGGwfbvpijibijtqFjLiVxxzR9Hcsg7qjNGMsy6OtYBnFHbcZYlqEUd3MvTBw6dCillNJnP/vZdPjw4ZRSSgcOHMj+Znd3N2vPs1oWtxFtwgpc0zGu03EdP348HT16dBwTQxlt/+677x7H3Dqdpy42Me776A8m1Y67e+65Zxx3bKdaMZdSc9zFe6h0Tw3RT/R9H1Omr1ucuO1u2+JOjCzfssdYttMy+7qdnZ2Z7xn6/2qmrnPnzo3/ffz48fTUpz51Y8bYGMsxdtdhjC0dw6qajKuUUrrgguaveI2x3TX10esSF6uibdzNvTAx6kwOHz5sYWJB674wMTL0PjfF3DqepzY2Me6HmpAsI+7YbjXuv6a4szCx3fR18xO389uWuBMjq2NZYyzbbRl9nYWJ7RK/QE5pc8ZYCxPL03ZhYsQY256Fif6U4m7uhQkAAACAZdmU/8kPALaR5R4AAAAAAKAaCxMAAAAAAEA1FiYAAAAAAIBqBq0xUaPIzToU0oGuxDUAAAAAsKn8YgIAAAAAAKjGwgQAAAAAAFCNhQkAAAAAAKCaQWtM0E6sJ5CSmgKz7O7ujs+Z8wRQj/o3wCbStwEwpMlxpun7H4Bt5RcTAAAAAABANRYmAAAAAACAaixMAAAAAAAA1ViYAAAAAAAAqlH8GlgKRd9h/SkYC/Rhd3d33J/oR6hF3AEATRSpr8cvJgAAAAAAgGosTAAAAAAAANVYmAAAAAAAAKpRYwIAgI2lFgoAq8bYxLYQ68AsfjEBAAAAAABUY2ECAAAAAACoxsIEAAAAAABQzcI1JnZ3d6dyxgHduIeAvjX1K3K6ApTJhw0MwXcnsJrW9b5c1/1eRc7l8vjFBAAAAAAAUI2FCQAAAAAAoBoLEwAAAAAAQDUL15gAAOqTAx0AYDOtyzxvXfYTgNXkFxMAAAAAAEA1FiYAAAAAAIBqLEwAAAAAAADVrF2NCTkMAQCGZ84F0B99Kmyvyfs/9gXrbtOOB6jLLyYAAAAAAIBqLEwAAAAAAADVWJgAAAAAAACqsTABAAAAAABUY2ECAAAAAACoxsIEAAAAAABQjYUJAAAAAACgmguWvQMAAAAppbS7u5u19+3bt6Q9AahH3wd0FfsNWEd+MQEAAAAAAFRjYQIAAAAAAKjGwgQAAAAAAFDNwjUmdnd35TUDAGDpzEkBgFUzOT8xV4HV5z6txy8mAAAAAACAaixMAAAAAAAA1ViYAAAAAAAAqrEwAQAAAAAAVLNw8etZ+igWsg0FR7bhGPu0DQXX4/Ht27dvSXsC8BX6JmAT6duA2vQ7sDo2/fslWGV+MQEAAAAAAFRjYQIAAAAAAKjGwgQAAAAAAFDNoDUmAIB+xNyncqGyjeTkBgDWzeT8Zdvm8Nt2vDU5t2wCv5gAAAAAAACqsTABAAAAAABUY2ECAAAAAACoZuEaE7u7u/KawcA2Iaf2JhwDrLIh7jHjO5tAHAMAfWmaV8R59zbNPbbpWIH++cUEAAAAAABQjYUJAAAAAACgGgsTAAAAAABANQvXmAAA1oNaLyybGKTJZM06MQHAppmc/6jJQF/E0nCc23r8YgIAAAAAAKjGwgQAAAAAAFCNhQkAAAAAAKCahWtMTOaEbXqtb6VtyksLwDZYRt5LuTahrOk+MT8FGMa69rnmVNAfNcxgffnFBAAAAAAAUI2FCQAAAAAAoBoLEwAAAAAAQDUL15iYtIyaEptgG46xT7PqmmwKORKbTZ6XTY8BWAf6qs3m+rKpYmybUzCETYgr48DqWNdaGtuidL9v8nNs1+Ppo1+J23jsscey9sGDBxfa3rpY1/1eB85tPX4xAQAAAAAAVGNhAgAAAAAAqMbCBAAAAAAAUM3CNSa2Id8/0D95UqFscoxdNH9rSu4xtlOpnoD7YrUt43qJke0wOcaKK2qYNa8TD5ttZ2en8d811O7rmj6/b/E4Lr744k7v35TvMDflONhufjEBAAAAAABUY2ECAAAAAACoxsIEAAAAAABQzcI1JmbpI9/ZNuRelBeum02sa7JpxzOvbbjfoS/LyJuvr9p8mzjGsvo2Mf81QBfrUA+pqa9cxf1kWKVYXYZF424VjmEeteuVbLJVjOtt4RcTAAAAAABANRYmAAAAAACAaixMAAAAAAAA1ViYAAAAAAAAqlm4+HXtIoml4kqbUnxpU46D+Wxi4Z15YnpVj9v9uV1G13vV4nGI/Vm1Y2S5NiUeNuU4Ntnk84QxFtgG+rrtMlmkuHbB4skxdhlxZh4GzOIXEwAAAAAAQDUWJgAAAAAAgGosTAAAAAAAANUMWmOij1xy21BTQs69bmrXNQFYBaV+r8Z4WKp/swljMu0t43p3vQ+WoWkf3AuzLXtutwr9K/Xt27dvra+lvubLVqHf78M8x7GKfdMq7lPf5rn3Jt9TO2bPnDmTzpw5k1JK6eKLL+59+6twD3aNs02p6dl2/rKux7dMzlk9fjEBAAAAAABUY2ECAAAAAACoxsIEAAAAAABQzcI1JnZ2dtLOzk4f+7Ln9ift35+vpWxizkJmW3Ye4ho2/fhSWr/cnLBq5sm1X6rTVNqG+267lOZg81jFuhQ1bEPO7UVMPk8cOHCg9+13jQHXazs88sgj47i74oorBv+8VeiLtsWq3sOTz7HrGA/ruM/LEs/V+fPnG/9dw/79+8dzuK73Rptrvg71vzZV6bvY0fVdlT5wnYjbevxiAgAAAAAAqMbCBAAAAAAAUI2FCQAAAAAAoJqFa0zMyvc/T06uWbn4UuqeH3sdbMIx1DR0XZNlKOVx34QY6SPXqxoTbJtZuYhjO/aLTXnaF70P3Xf1LCsH9eQYe/bs2ey1GFPx9QsumJ5WluZti+Y6bjMvrJ37eJ4aSn1bdA5ee551+vTpcfwcPnw4e22Ic7eJ8yy6u/TSS9Oll1462PbXMc7WYR+jddznlMrztlWsk9HmXK/Cfi5D6dxMfq9Ve4y94IILxmPsENendDxd+8JFvydo2kbXfVjF+69J7Xolm6xNjKxLXKwbv5gAAAAAAACqsTABAAAAAABUY2ECAAAAAACoZuEaE5O5iEv5rudx5syZrN2Uv3iWVcwBto75RlfJuXPn0rlz51JKw1zfVYiZbYiJRfOA1z5Hs+rpQA1dazDt3z/9/x4s2p9t6vi1Cv3+qjh79uy4dkSsIXHq1KmsfejQoaw9T+7prjEU4zpur+naLVrXoqs289+m+7NPbc7rrPNSO//1qVOnxuck1pio0c/E492Uvo3Z+p7bdc1Zvg5jzzrs4zqZjLnY73StsdT0nr6vV2numVJzTbMh92kZ2sx/S9di9P1F/HcN+/btG/S8d60xUdJHv1y6ZjGW56ndtwrUmBjOptW1XWV+MQEAAAAAAFRjYQIAAAAAAKjGwgQAAAAAAFDNwjUmzp8/v2des1K+szY55u+8886s/cIXvjBrx7xfpdzDq5jjsCl3WSmv3irs97IcP358fH7iebr00kuzdpvc09Eq5BMs5UTchPhok7MvHucTTzwx/vfjjz/e+z61FfOCxn6n1A8tQ5tcqDTbq7+p9dl75SKOJu+PlJqvb4zNrvmw47heqvsk7vbW9tzXjrv9+/eP4+TgwYPZa3GMbdPXxf9WmreVxBhsE9O1c8Q2zX/nmY8MbdYceegaGNG11147ri2xjLn6on3bKlxPunvooYfGtXSuvfba7LU+7tnY9/TdFxljv2yemjpd3tunyfqcUeyHFh0vm7YRn2u75uF/6KGHpj7jiiuuyNoXXnhh1t6EmOwjTiZrp8Y6qkNbpMZEm9pdpTpNNeo4lbYZ9yHWTYvfLVx++eVZ+6KLLpraZtd7coh7IT7/0V7X/o/h+MUEAAAAAABQjYUJAAAAAACgGgsTAAAAAABANQvXmDh37tw4N2fXXHFtchFff/31WTvm44s5DOf5zGVb19xly8p/ffjw4XEe4pjrr4996VrPYdHtpzQdA6UaBkPE8aLHWTpvo35ipOnejcdZOy94WzE/6yrmDt8U257HezLff7w/Hnnkkawd8/8/6UlPmtpevA9jHvVSXaZSvuw212vbr+lI6bhHr9fO9T+ZhziORaW80W2uZd9jTZvXh8jbPeszT548OfU3x44dy9q33nrrzG12vS+WUQOnTwcOHBiPrfF69dFnlOYopb6stA9y/a+n6667bvxMEWOgjziL24xjcNM4veg+9K3rvdBmG30fV5t6jXvds8us4xTH2FJtmzZK43LXOoVxn6666qqp96z7+NNGm9zzpZpXx48fH/+7aZ4wpFm1Tea5fnFb8Tu6uM34+iWXXDJz+/PUjSldo9j/3nfffVn7r/7qr7L2q1/96qzd1G91/U6g7dy/i9iP7HWdV/V7lVWixsTy+MUEAAAAAABQjYUJAAAAAACgGgsTAAAAAABANQsnMjxz5sw4Z1wpp3zUJnfc1VdfPfV5k7rmt15GbutS/ruYF67pb1bhOFbFE088kR5//PGU0nRO9T7OQ8wV2Lc2Odf7yOPex37Nsug+tMnNGa/FwYMHx/9uum+GtLu7u2c+2lW8/zY13+sy+/BlnNPJnLBx/IsOHTqUtZvG4NL5Ko1XcR9ifux1uDearMJ+73Xua+eEfeKJJ9ITTzyRUkrp9OnT2WtXXHFF1p7nPJXyuHeN0dL2U5q+F0q5jbuK+xTzFqeU0jOe8YysXToPQ/Q3Xc7dMvPqDnFuFq2D1TUve9N71qU/3CaTz7Exl/489Wxi7I760pFHH300a8c465qvvKm/67suUakmT5v6KkPHfpsaE3u9Xntud/bs2XF/E/ud0vVdhT6kTV83T385tK7XuTRGND2HxjlxHEf//d//ffzvxx57rNP+LGqyfljXsanNuRt9N7PXNuP5i+cm9n199GNxG7GPv+GGG7L2i170oqw9qj800lQTqO8aErH2yGWXXTbz71OaHlf2+sxl3Xej+FmF/qukVDslpeHndkPUHloHfjEBAAAAAABUY2ECAAAAAACoxsIEAAAAAABQjYUJAAAAAACgmoUraTz44IPjwl5HjhzJXotFbtoUzol/E4vMnDp1KmuXiuVGq1B0JR5jLIzW9Dddi2H34cSJE1n74osvztqj4jBN+z+kgwcPThW9XidtiuXFQjtDF+TuQ9ci7033YqnA3uR7at/Lk8WbuhajW8V+J6XV2K+uahQT3asYfe0ixCl9uTjcqEBc7GsfeeSRrP3kJz+5uL1Scbl4jLE4XSzKFsfoNgW6ul6zmgXOl7n9vfrQ2oU5H3300XEcvPe9781ee/3rX5+1Y8H1pusfr18cC+J4XhpL4n0Qi8c2zUnimLpoYda4T/E+eupTnzr1nqaiibO2uejrTf1V6f6eLF4Z54BDm+zr4vNDNE+fEM9PPPb4fFEqStymMOeic/V1HKPXzRNPPDHuM2L/Fe+XUjul6b7m/vvvz9of//jHs/bXf/3XZ+34rFWKu6Y4LBVULikVpW2j7/lSaVyI929K0+cyGl33puKmQ5o1r4vtNue+NJ71/YzSFHMxZmJ7FeZxpRiK+xzj4p577snal1xyydRnXHfddVk79im33Xbb+N9xPj20yefYRc9VStPnKz6TxO8F45wiFpaOMTLPGFt6vTR3e/DBB2dur82z9KLf2c3zHddnPvOZrP385z+/8e9qP0+UPn9ZxbhntWNcnz59uriNvq3D935D8IsJAAAAAACgGgsTAAAAAABANRYmAAAAAACAahauMXHfffeNc+Q9+9nPzl6Ledqe8pSnZO2m/FylnF3Hjx/P2pdddlnWjrn8hshdVtpm6Rhi3s2HH3546m9irvDScQ1xnPHcRqPjaJNTvE+PPfbY+DNj/tDSua+Rj36ev495LGPeyZgD8eDBgzM/YxWOM8Z5zJvatL1STr02+SaHMpkTNuZIj1YhN2DMkdiU7zfmPF+HfNalOiTzaJvTvnY9nZS+nNty1N99/vOfz1770Ic+lLVjvv8msc+MuUzj+Z3MOZ9SSh/72Meydhz3Y37dmKc9pXKO7K75WPuI25iTu2tczVMfoFQTYHQP185/fc0114xz/77pTW/KXosx1uY8xeN67LHHsnYpr3vsy0rvb8oHe9ddd2XtGPcxTksxuWhO77Z/M2uf+hD3YfK8lGpi9G2yr4v54uOcJ/ZjTeeydH/F/vzOO+/M2s961rOy9pVXXpm14/lpuj6la9b1eWIVx+hV3KcuJvOex34hzuXazO1iXMT2VVddlbXjs1bXmGmal8T97Bpnpbp38Tw17fOidXtK4j7G7wdSKtdAGvX7TfOUIe3s7Iz3/6GHHspe+/M///Osfccdd2TtNjnuF60pMc/rMQ5jH73o+NVmXrhoXxTvm3jvPv3pT8/aTTVMSvfS5HtKtZT6dubMmfG9XHruKc3DUpqei73//e/P2m9/+9uz9gc/+MGs/R3f8R1Zu3S/NvW/XZ8fSvUD3vjGN2bt//qv/8raTd+/lOoA9X1/Nt1LL3/5y7N2PK7RNms/T6SU93dD1ORc9Hu40tzwC1/4wtQ2jh49mrX7/t5n3edV8/KLCQAAAAAAoBoLEwAAAAAAQDUWJgAAAAAAgGoWLg7wqle9avzvmMP3Pe95T9Z+xzvekbWb8rTH3GcxR9of/MEfZO3nPve5Wfurv/qrs3bMgxnzBTblBFs0d3Apd1nMyffud797ahtvfvObs/Yo3/NIzLu3aB7bNuJxjHIjNuVzHtJnP/vZcU7Wyy+/PHutj+Psmt886pq3MaWU7r///qz9v//7v1n7lltuydqlPIxRm/PSNUd6PI5STtpjx45l7aZ8+LEOzaz7tVTnoW8//dM/Pc5D+6u/+qvZaz/xEz+RtV/xildk7XhcKU3nJi3d0/H8xusR+5WPf/zjWftTn/rU1D689rWvzdqxv4z5T0t1Z6KmWI+65v/853/+56x9++23z3x/jJOmfMzxM774xS9m7W/91m9t3Nca7r333nG+9b/4i7/IXnvb296WtX//938/azf1C1dffXXWvummm7J2PD8PPPBA1v75n//5rP1DP/RDWfslL3lJ1o5jV0opXXTRRVl70fysffT7sa5P7Hu69o9t+v0YmzF2R/U9JnOg13Dy5MnxNYjXL8ZH6X5Lafr++sAHPpC1f/iHfzhrx3MXj/9v/uZvsvYzn/nMrB37iJRSeutb35q1//7v/z5rX3/99Vk75hGOOchLMdtUnyGem1WsHzC5T/GeGNonPvGJ8Rj0kY98JHvttttuy9pHjhzJ2k3nrjT3jnOSb/mWb8na73rXu7L2S1/60qx9xRVXZO2mfONtnjlmvd53buq+3tP3Z4xeb8pjPrTJ58jPfe5z2Wtxnlq675vMyjGfUrs+dNbrf/InfzL1Ny9+8YuzdqmWVOyj4/33T//0T1k79qfxXkhpepwv5YuP+xSPM9a7ivUZv/Zrv3ZqH+JYE/OCj+Ku9hh73333jc95vH4xHmI/FWtQpjQ9PpXqUnbtZ9r0EV/60pey9rXXXpu1SzV5avRDi87j2jxPxOem2P7lX/7l8b+Xke9/pOv5bvr7rt+HxXNR+h6hzTw6KtWwi/dGnOt93dd9XdYuPa+0+cxoiHE81vvb6x5exjxzsn5YaS7dx/6V7uO9nrVG/uM//iNrx7lhSindfffdWTvWV+x6XKsw/x/C6J5tc++m5BcTAAAAAABARRYmAAAAAACAaixMAAAAAAAA1SxcY+I7v/M7x3kDYw7L5z3veVm7lFu1SczfF3MJx5xel1xySdaOOQ3b1GZYNH91KW9wzK8W62KkVD6OrvnsonlqDuz1GU25lIf0a7/2a+PP/I3f+I3stSFyj0el3HWlXHZNOSVjPrvXvOY1WfuOO+7I2m9/+9uzdsz93zWvcUrlXI+lPLil/K+//du/nbWf9axnTe3DN37jN2btmN988rhq54R9xzveMd6fX/iFX8heK+XOXUbuwKc//elZuym/XykP7SqI+XRf/vKXZ+15xpUo3rM333xz1h7VnDh+/PhULvqh3XTTTeO4e93rXpe99k3f9E1ZO46PTX127BvieBTjJB7vb/7mb2bta665JmuXcnLvtV+TFo3Deca3GGeluOqj3kg893Gbo9y3pRpCfTt06FBjDaDRa5NK419K0/nH3/CGN2TtOHeMYg7g7/qu78raMWf7c57znKltxFo0sW5T1zon0RBzjyFqUHSJ29r5/m+99dZxXxefH2Ke53nmnbFvu+GGG7L2xz72sawd+744z2ozzq9CXuFVHNf30sd43tWnPvWpcb8W64H1cV/H+yjeg11jOb7/la985dTfdJ3bxW0+7WlPy9rf/u3fnrVjnzxP7Efx2sd2HC/j/fjRj350aptXXXXVzG2O9vH48eOd9nVR991337h22J/92Z9lr8U51Td/8zdn7ab5U/zOoFTfI/aFpTlZPG9NY8O9996bteNcIcbMMmpMlHR9vm96Do3nJtY2+pVf+ZVFdnEhF1544dR9NNK1/kZK03EW6xbGz3rZy16WtePcsPQdXZsYKf1N3GY8hre85S1ZO/YzqzrOx+8l9rrOtb+zS+nL53h0nhf9/nIepfMfYyB+BxBrK6Y0PVdY9DmtdP+tQv84j9H1bXud/WICAAAAAACoxsIEAAAAAABQzdy/Oxn95OTs2bPj/xZ/0hZ/vhZ/Ktn0U8CYHubkyZNZ+/Tp0zNfj/sQU0EtI5VTbMdUPvE8pTR9HPG8LCOVUzTap9G+9pHaos3+TMZcjKl1SOU0uf8jMa6jGDMxPuLPcpeRyinea/HejK83xX18T7x+TamcasXd5DmP52IVUzmVrmdK65HKKYrnfohUTrE9SlNWK+YmP2My7uJ9P0oFsNfrTdezayqn0pgcUwjEc7MuqZxK93Tp/fMoxd3oWtTu62altYjnpU0qp/jfYtyWjivGZIzBOD42jafxPfEYpXKaNjpHyxhj4zxpiFRO8TNKzxPx/VI59a9WzE1+xuR1juPhOqRyakoPu2gqpzjux3slvt5HKqeSvcbHkaa0OqVnoZjKqVZfNzkGls51HC9jP9W0jRgTpTRZfaRyKs1HS99jrEI/1fX5vuneK6VyavO5fWszt5snlVM81tI8K8ZEfL1GKqcoHkOM49L3TG0+s0Zsx3nvXtd62WNsjVROXZ8pSs+5MVV5StPnt6kv6NMq9I+LaBt3+3bnjMzPf/7z6ejRo/O8lQ11zz33pBtvvHGw7Ys5mog7ahs65lISd0zT17EM4o7ajLEsg76OZRB31GaMZRlKcTf3wsTOzk46duxYOnTo0Nqv4rCY3d3ddOLEiXTkyJFBi9iIOSaJO2qrFXMpiTu+Ql/HMog7ajPGsgz6OpZB3FGbMZZlaBt3cy9MAAAAAAAAdKX4NQAAAAAAUI2FCQAAAAAAoBoLEwAAAAAAQDUWJgAAAAAAgGosTAAAAAAAANVYmAAAAAAAAKqxMAEAAAAAAFRjYQIAAAAAAKjGwgQAAAAAAFCNhQkAAAAAAKAaCxMAAAAAAEA1FiYAAAAAAIBqLEwAAAAAAADVWJgAAAAAAACqsTABAAAAAABUY2ECAAAAAACoxsIEAAAAAABQjYUJAAAAAACgGgsTAAAAAABANRYmAAAAAACAaixMAAAAAAAA1ViYAAAAAAAAqrEwAQAAAAAAVGNhAgAAAAAAqMbCBAAAAAAAUI2FCQAAAAAAoBoLEwAAAAAAQDUWJgAAAAAAgGosTAAAAAAAANVYmAAAAAAAAKqxMAEAAAAAAFRjYQIAAAAAAKjGwgQAAAAAAFDNBfO+cWdnJx07diwdOnQo7du3r899Ys3s7u6mEydOpCNHjqT9+4db6xJzTBJ31FYr5lISd3yFvo5lEHfUZoxlGfR1LIO4ozZjLMvQNu7mXpg4duxYOnr06LxvZwPdc8896cYbbxxs+2KOJuKO2oaOuZTEHdP0dSyDuKM2YyzLoK9jGcQdtRljWYZS3M29MHHo0KHxBxw+fHjezbABjh8/no4ePTqOiaFsU8zt7u5mbSvN08QdtdWKuZTEHV+hr2MZxB1DiXPckePHj6ebbrrJGEtVy+zrSs97ngc3y+T1rNXf6ev2ttdYtJd1vf9Gx2mMZUiLzu3mXpgY3ZiHDx8WbKSUhu+stynmTETbE3fUVuN+FHdE+jqWQdzRt9KXQcZYlmEZfZ2Fie3S1PcZY5dn2xYmRoyxDGHRud3cCxMjOzs7aWdnJ6WUBs9VBil9OehHgb+uA0QUb+RVeGjrW5vBfx2PC2rZxH4BavDlznpZxvUSI/XsdW6dc7bB5HPs6DuUvRw4cKDGLi1M/9ls1vN91y/FV906LrKtwz62EfuR+J3s6DjW5XhWSVMf7TvvZovO7ZxVAAAAAACgGgsTAAAAAABANRYmAAAAAACAahauMbFs65oLbtIyCiGts02sMVHKcQiwCv3EJoy5AJDSZj5TsL7E4GaJ13MyX71n/dWzrs84Yqk/zuXy+MUEAAAAAABQjYUJAAAAAACgGgsTAAAAAABANQvXmJjMzdn02qR1ydMGtcV7xb0DRKvQT+iLgG1gHgbAIrYpX70xE1iEX0wAAAAAAADVWJgAAAAAAACqsTABAAAAAABUY2ECAAAAAACoZuHi17VtUxEh2CSKYsH6K43B7mtgHZmjAMvme47NYhxZL+4/4j0rJurxiwkAAAAAAKAaCxMAAAAAAEA1FiYAAAAAAIBqVr7GhLxesBnk2QQAAPrU9H3BJjx3qH2zWSavp++46ItYYhP4xQQAAAAAAFCNhQkAAAAAAKAaCxMAAAAAAEA1K19jArZBKWeoHKMAAACbyfPdZpu8vtt2rX2XMRznsj8xTtXvqMcvJgAAAAAAgGosTAAAAAAAANVYmAAAAAAAAKpRYwJWQCl/ndyBAFAmHywA60ge/s02eX03ba6yacezTpx7NoFfTAAAAAAAANVYmAAAAAAAAKqxMAEAAAAAAFSzcI2J3d3dPfOaDZEnMW5DTrXtMyvmNtUm5BzdhGOAbec+Zh2JWwBWjbFps23b9xUsR+n7Uf3K/Jy7evxiAgAAAAAAqMbCBAAAAAAAUI2FCQAAAAAAoJqFa0zMIicX9MO9BKwCfRGrrilG5XkGAIYkt/96M1dEPePl8YsJAAAAAACgGgsTAAAAAABANRYmAAAAAACAahauMbFv376q+fPk+aJ2zNUgroFF1chtK38uq854uv70K8A22JQ51bru99DMRzZL0/VcxdjflH5lGeK5cw/X4xcTAAAAAABANRYmAAAAAACAaixMAAAAAAAA1SxcY2J3d3ece6uUk2ue/GalvF6bkDNtXfLVrYrJmNtUQ9xLwHrTL0BZ032w6XMGFqc/BWARcdww9/iKTXiGWYd9TGl99nMduIfr8YsJAAAAAACgGgsTAAAAAABANRYmAAAAAACAaixMAAAAAAAA1Sxc/HpSjYI/irmwDRTaAaI4/u3s7Mz8+6Z+xBjKuisVTDR+rr91LIoJ0Mbu7u6e41Rp/FrVed0m9Nmlcz/PMa3jeZiXudfyOPdsAr+YAAAAAAAAqrEwAQAAAAAAVGNhAgAAAAAAqGbhGhOz8iQOYRNyGLKY2jG3CjbheN27ACw6Fqzr2GEMhNUz+UzhnmTVGDfq6Vqvap5n88n3bMKz/SJWMZbX4Zo07eM67DeU+MUEAAAAAABQjYUJAAAAAACgGgsTAAAAAABANQvXmFi2Tci9KC8c26gp7tfx/mXzjWJ12X31sj+/aR/cs6yDVbh3aK9GPyMmoB3j/nA2pR/ahhiJx9jmOXbWezbl2s9rG2Kmlm2PpSE5t/X4xQQAAAAAAFCNhQkAAAAAAKAaCxMAAAAAAEA1g9aYkJMLGNEfwPLJ6UrJ7u7uOE5WMT7EMEMwR4Fm69DHqltH38RPN6UxdB3G2HXYxzbELuvILyYAAAAAAIBqLEwAAAAAAADVWJgAAAAAAACqWbjGxGQu4iHyspVyCW9qDjU5lPc2GXObahOOb55jKMX95OubcI6gT8YN+rBv3749Y0eMAZtkG54pFqXfH47YW1+LPue69syjqf/d2dnJ2vrs/rhP6/GLCQAAAAAAoBoLEwAAAAAAQDUWJgAAAAAAgGp6rTExKx98X7YlZ9qmHhfMsi5xvy39EKttiDgsjdvxdfcC0LdV6Gf0bQxBXNFFm3jp+n2L/rMfba5FbE/WAoh1AdbdJuTiX9djWNf9hkl+MQEAAAAAAFRjYQIAAAAAAKjGwgQAAAAAAFDNwjUmhlbKUbgJOQzlhaOUk1KMACV9jIc1akWx2mbVDltXtePYfdOvefqlrrHbtb7OptwbQF2TY2wN+qphNF3D0nU9f/58479Zjk2Zq5mfsAn8YgIAAAAAAKjGwgQAAAAAAFCNhQkAAAAAAKCahWtMTOZJ3JQ8bay2nZ2dtLOzs+zdGNQm3ktt8h+u8nHXzgkLUY3aM2KcbTB0Pt51G99WTamvkz+ZGrY17vRV9dQ419saxyWl8xK/a9i/P///eZuuXfybc+fO7bnNVfouo48Y6VqnaRVsSl29GEvu+fmp87o8fjEBAAAAAABUY2ECAAAAAACoxsIEAAAAAABQjYUJAAAAAACgml6LXze91rdNLECyicfE3jb1enc9rnnOw+R7NvU8QlvzFJorFUArFYJz30GZ+6S7yeeJWEC06W8ntSk2Xur7StdM8cjNNOs5to9rPnRfMM84v4nWtc/t49lpG693H0rz3dI41GbcmdWuHbOTfV3c9z6KXa9j8etoHfaxiWLXw1nXmFhHfjEBAAAAAABUY2ECAAAAAACoxsIEAAAAAABQzaA1JvrQNd/fpuSIlStuc7W5lpuY132TY3qTj431MU8cLtq3bELftKpG53aZ53hnZydrr0Pf1nS+uuY+Xofj3DSTzxMx7g4cOFB8b1TKH95mf2a1xchm6FIrcYiaE+Konpo1MdvalDnUojV9hrgPVuHcxuOaHNviOFdTH9+XbULftQox0gfzleFsSoysA7+YAAAAAAAAqrEwAQAAAAAAVGNhAgAAAAAAqGbhGhM7Ozt75sjrIyfXNuRMk7usm6HrmgxtnvzXm2ieY17V3JylXNab0E9ts2Xm+p/s71ah9oxc/cNZlXFg3759e163Pq7vMmJkHWupbPO9FMf3Un25pnPTta/qWteCzTDrOZb11rYPrd23zqqn0/S3k2rUYuhaH2Ieix5Hm7pCXQ3xLHfBBflXbefPnx//e5n9TtcaTG3Od9dY7hpHbcb5oe/leeKuxncGk3E1ax9W5TljlcwT+wzDLyYAAAAAAIBqLEwAAAAAAADVWJgAAAAAAACqWbjGxPnz58d5zWJuudieJ4dazJm2iTl229Qc2MTjntesnOtRmxyKi+b66/r3ba5l13x265Czu80+rkIO/Ta6nt8hcqF2tQr7QHeT+f5LY+o890vX/q1r7nfWz+S87uzZs9lrF1100dTfTmqKhxhjffc7beK+a72yZdSkGPo8rbqTJ0+O4+fiiy/OXov9To0869tqiPlk23O7jGuwf//+cdzVyDW9jnHW9VlrGeYZB7q8t0+znmOXcS6XUbeiRl2Lvrc5zz7MmnvUjrvJejpxrjbPHKj0fFCadw0RA4veT3FO28c1r1GHsnQtRp+xjuNPbaVzyXB8owAAAAAAAFRjYQIAAAAAAKjGwgQAAAAAAFDNwjUmJvMkds013SbPWcxvfODAgazdNZ9/m88cOr/jPHnBVyFf3SrkEE0pz3/dR/2Hvmsl9JG7uo/cj13/vu/8n6VjmGcfJvP81c75N9nXdbWM+3Gefmbo3O+r2i+1vWeXkZtzVi7i2I65UeN42aRr39L19VUZNxa1jBzby4q7s2fPjudeZ86cyV47ffp01r7sssuydtO+xrFg0Rgp1WJo2ofSeLHoPrXJSbtojJTe32ZM7HK/1x5jH3jggfTEE0+klFK65ZZbstfmueZR6T2x/+xaT2eIGmaroI884G1jdxlj7OQzRdfn2DZ/H+Po3LlzWbvNON1l+31scxmWMcddhXzrpeNeRv2HKMbYqJ+edOGFF3b6zJJ56hH0PY6XtBkj47hy4sSJxn/XcODAgXHf0HVO1NTXta1r0NY88+yu74n7GL9njNrMA4aOuzbbi8ex19i0jDnHqn9/UhoX4pjdZpuL2tbvT/xiAgAAAAAAqMbCBAAAAAAAUI2FCQAAAAAAoJqFa0zs7OyM86/FPGyxPU8thU9+8pNZ+wUveMHMz+iaH7TNPnTNSdk1Z1dT7rKLLrpo5ntWIU/tsvJfP/LII+OcjTF3Y8x3HfOstsl927WuSR/XopQDsRTnpfeXPi+lxa9j6bhLecZTmr6e8W8m85o25Tgd0mSOxLifpevRRy7URfOwb4oax7VXbttVqzFRyl198cUXT23vggvyYb9rntn4GXF7pfc36XuMHaKmzqK1OOaJ273mVkPbv3//uE+Lc5E4xraZc5VyRXedt5X636bzVRpbFp07xuvbNK+L90rpMxet69Sm1sYqjRNHjhxJhw8fTimV5zzz5L/uu93G0M8T8/Qzy+jrVrmO04MPPjiupXP99dc37tfIPPdLKY5K92Tfc8MmXc97H7UausZdH7VN9qorE8eHoe3bt2/P44ljR2m8a1K6HnEsKh1/fP3BBx+c+purr746a8eaE333favQ181TT+fkyZPjf586dWrm3/Ztsp5O6fuRec5vKY5ibD/pSU/qtA/zfI8YPzO+fvz48az92GOPZe0rr7wya19yySVTn7no83nX4276vNJ3Ist6nhh95uhzS/WP+phnRYve58s4Z0MYIu5KusadX0wAAAAAAADVWJgAAAAAAACqsTABAAAAAABUs3CNiXPnzo1z8rfJ8zupTa6qmO9zlAd0JOY/HiInYdd8Z6V8oW223zX/cR+5OKNVyj086fLLLx/nIY75CfvIE9r1evWRazXGTMwVGD8jHndpH/rISVrK+VyqixFrd8T8o03bjPs0mZuwlKdwSHE/a+xLzVyAbT8j6pobucmiuY5L22vafh+1iYYyKxfxI488krUPHjyYtWM/kdJ03xJzDZeuedfaUW3Od9dr3nedp3l0/Yx5xoXRtSnV8ejbZI2Jxx9/vHGfulj0Hi2NNXH789Qb6DpfLe3DZB7pkWPHjmXtW2+9deZnLpo3t+m8l8aqyTlU7Xz/F1544XheUKoJEo+j6fp17ctKc5R55lWl/rJ0bwxRE2TRucQ8tTjazlGXMRZff/3142eKrvn8m545SsdayrPeta9p0vW5JSrVzGmzD8uoyxTF67PXWFE77iZz/ccxtunZaNI8z3NdYyq+P47711xzzdRnxm12vZf6zhPftE+Lzj1Lz+opTd/PcayaHGfimDO0yeeJ0tg0z/hfqucQjzc+s0Rt6meW5m6la/bFL34xa3/gAx/I2j/6oz86c/spTd8fpXlWKQ5Lz9JNxxxrY6xKX5fSl8/H6Jx0rZnaZj6xaC2uUgw11Yzru8bxEPWs+v6eaJ55dte4W91vYwAAAAAAgI1jYQIAAAAAAKjGwgQAAAAAAFDNwomLz549O84ZF3PHxXabnGAxN9VVV12VtWONiZj3q5T7vU1OsCHqNcz6+9o5BlPqnl+t6T3L8vjjj49zOF5yySXZa6W8fW2udymfdSlPWh/5YKNS7YzSMfSRK7prTsT4ejyGpriPuVXjNiev9zLum5EaORoXzS09T77QUh/ddy2ANrr2VfPk5hwit3Ffzp07Nx7nYszHe2qUJ3uk6R4p5fMs5Z2NY/DFF1+8167vqe8xto86P4vuUynu2uQij0bvacpvOqQzZ86Mr/OJEyey1+KYO0+e1dJ4NkQNkphXOMZt6b7oen2/9KUvTe3DM57xjKzdtY9ftC9MqVxnYfI81M5FPNnXda0p0eZYo3jNSnOUmEe6lL++Sd/PE1GbuXzpM7vmJe6jrxvt9zz7v6jHH398PPeM/ULXPPlN74k1BB5++OGsfd1112XtUn7yNuNdqT/rap75ZN/1wkp/3xR3bfuw2vV0JsfYUg78NrU0u+Zcj5/ZpfbQXkq1nmrUb1y0VmJpe/Febvq80jjyL//yL+N/x7oAq6RN3dj4306dOpW1r7zyyqwdj/eyyy6b+ZkxBpritOszX/yMo0ePZu2XvOQlWTseQ1PtvkXF44r1A+OzXdN5iOPKXnWBljHG7uzsjD930e/YmsxT63BSaSyJz71N71l0bhePO16/PmqZLjrGLlJDt23c+cUEAAAAAABQjYUJAAAAAACgGgsTAAAAAABANRYmAAAAAACAahYufn3fffel06dPp5RSuuaaa7LXYgGnNsWWYqGNWGQmFh6KBUpKBfHaFPJYtGBXqbhg/PumAqXxPaXiMKXCLV2LtKSU0vHjx7P2pZdemrVHxWBqF286dOjQuBDQooVc2vxN10Kc8xQWj38TYyLeB10L8s1T+K5UBLd0nKXXm85L6bgm31O7IOykUnG6qClmFi2uW9peqfh4StNx1bU4U6l43TxFrEpx1/Uz5ymYF9ujWFtGzJ0/f3587eI1fPTRR7P2VVddlbWbjj2Ou7FdGp9iMeRYsD4WiG0a50t9YtfY76N4Winuoq7FQJv2qdQnju7PeE6H9uCDD47H9/e85z3Za294wxuydixe2LSvMQZiIblDhw5l7dK8Lt6Hsf9tmpPEOI77VOo3us7Jnva0p03tQ9zPUhHAUt8Wz0OpYHRK0+c+npfJbcQ54NAmCyTGIprx3MV2U9x1fR6I/WlpfIzndxnPE6X+u0nX/neewsddt7lMk3EXnzEvueSSrB3vl6ZzGf/mS1/6Utb+8Ic/nLVf+tKXZu1YgLt0jZvu81J/t2iR4DZxVpqDlvap9DwQ9yEWjE0ppWuvvTZrx+Ma9YdxTj+0yXld7MdjDMZ+KMZkSuXCqPH1RQvgNl3/vYrtjnQtNN319abPbPMcNOv1GBf/8z//k7Xj9yIppXTLLbdk7csvvzxrf8M3fMP43ydPnpy5P0OKfUQcQ9ucuxhHDzzwQNa+4YYbsnYcY5/ylKfM/MzSGL7Xf5v1eozDeNz33nvvzH1oM86XYjV+ZrwWMWb2eiaddNddd2Xt2267LWvv9RxZw+7u7vgY4r6X4q6pr+r6/UnX7y7iPjbNheN33vE4un7v2seY2/UZonR/tYnreb7znMUvJgAAAAAAgGosTAAAAAAAANVYmAAAAAAAAKpZOHHx/fffP84F+9znPjd7Leaai7nk2uTrjvmsHn744awd8/uVcjG3ybM4T47y0jYnxfxu8ZhSms65HPN4l3KwlY6hlOuzaR/ie0Z5UGPO4qGdPn16fJ3jPpZyvDXl1ovH3rU+R+kzSjndUkrjOi0jMY973MeDBw9m7VIeuK75ZVPqnouudB5iDsWmfKOluJ68vrXzrp87d27cZ5Vyc7bpQ7rmiu5aw6NN3r9SPsJS3LTJ/znr/U1Kcdem75r1/jZ5GuP1XWaNiccff3zc/8ccov/wD/+QtWO+/6ZjjX1HPKZSvZuPfvSjWfuZz3xm1r755puzdsyPnFI5v39J11hvkxczjmMxj3OpxkDpXmkTO3GfRvmHa+chvuaaa8Z1nH7sx34sey2OuVFTvZ147HF8u+KKK7J26frFHNyx/206X3feeWfWjvdKqVbKrLGoSZuY7lqvKrZL+9ikNHeY3EbtOgCnTp0an7c4J4pivxJrUqRUntvFOPrP//zPrP2c5zwna990001ZO8Z6U38br1Fpfhl1re01j9LcLe5D6Zja9Ld7Hfc89dAW9dBDD43Hueuuuy57rXTsTccaa0TEY4rPwrEvKj2nxthvulfi33Q9r3vNgUba1BaKSn/Tdf4Z79+m8xDH9b1q09R+njh//vz4nMYaJO9+97uz9jvf+c6p90alvq4Ux6UYazN/ifUYSs80cZ9Kn9km5/qide/iPsd9euELX5i1473eZNZxNs2PhzT5/Uk8F/H6tXnWirn3f/EXfzFr/9Zv/VbW/sM//MOs/brXvS5rx/llnIc33add6+XEPiHOR3/qp34qa7/kJS/J2k9+8pOnPqNUt6JrXMZrUboXUkrp+77v+7L27bffnrVH57KPOcMiSs/4beoRd63p0WaOMinWqbv77run/ibOB7v2LV2/y2iyaC2Nkj7nl23nIH4xAQAAAAAAVGNhAgAAAAAAqMbCBAAAAAAAUM3CSRW/+7u/e/zvT37yk9lrv/M7v5O1f/ZnfzZrN+WuinliY56v97///Vn71ltvzdovfvGLs3bMTxfz6zYp5QkrvV6q5xCP8dd//dentvGWt7wla4/yPY/EvIRxn2I75tSL+ZSbcnOWcic++uijKaXpHINDu+uuu8a1ReL1j0q1N1KazqXapg7JpFJu0pgrsGkfYo7RD3/4w1n72c9+9sx9jLVWSvvcR/7reN5KNSU+/elPZ+2YozallG644YaZ+zl53LFvGNprX/va8bX+y7/8y+y1V77ylVn7B3/wB7P2kSNHprYX+6IYR6V8gzHnZMyr/q//+q9ZO/bPKaV0xx13ZO14TWLsXn755Vm7a27/NvkNY9zEvumDH/xg1v6e7/merB3PW4yTuP2UUnrwwQez9uc+97ms/QM/8AMppeXk5rz33nvHY8Yf/dEfZa/93M/9XNa++uqrs3bs51OajsV4z8Vrfv/992ftn/mZn8naMYbiuBHHrpSm8zzHa1Zql7Tp3+K1jHES97GUyzOOsfHeaMrRXMq5/Mgjj6SUpnPgDu3kyZPjfSvVJInH3TQfiHOeOI/78R//8axd6gP+9m//NmsfPXo0a8daASml9Na3vjVr/93f/V3Wjrnl49wxxnWpTkpT7ujSmNl17jFPTtpSDZnJbdaOu4985CPjucxf//VfZ6/FPM+x/kObHPHxeP7v//4va8exJMbl937v92btOB7GdtN+dZ27R7PmRHuJ1zyOC13rxMUxImo6hlKO7FHf15Q/f2iTzxGf+MQnsteuvPLKrF2q0dL037qe/1Le+Yceeihr/+mf/unU37zoRS/K2vEZoVRv5UMf+lDW/rd/+7es/ba3vS1rx7lHStNjaCkPezxPcZ/ieb3vvvuy9td8zddM7cPv/d7vZe1YE2vU/9Wu4/SZz3xmPN9+73vfm70W4yH2U9dee+3U9mLMxHaMuVLNv3iPx+013acxD/v111+fteMYGq9/PO555ttda/WV+pu4j/G8NI07o+9GRmIcT947Tc8jtZTqr0RN5yr+t7iNeL7jfRbHhdL1aBp7Ss/OMbbjPsa6Fk996lOzdpwLNuXKj/dH6XmhVLMlHlO8f5vujXi/xdgaHfcynmNPnDgxPm/xfMf9jOeyaX/jNY7ns1TTKt6TcW4Y6ze++tWvntqHj33sY1n7Gc94RtYuPUOWaiiVng+blJ4pSt/JlGrpNd2fpe+8R+3SvHHELyYAAAAAAIBqLEwAAAAAAADVWJgAAAAAAACqWbjGxCtf+cpxPrCYNyzmxY+a8mjGPGoxd9Xznve8rF3KYVjKadgm11opp2sph2F8Peb6jLlAU5re71Luv1Ke2niu4z41bb+Ui3F0HubJc7yId77znePr+L73vS97LcZLKXddStO56drkVJv1mVEpT2pKKf3jP/5j1n7jG9+YtWN+u3e9611ZuxTnpRxwTX9TykUdz1s8zi9+8YtZO9ZSedrTnja1D7fffnvWfspTnpK1J/uH2vmv3/e+943z5cfzF+OqTa7wUk7KUo7KUlw+//nPn7m9lMp5GEsxUbr32+RELLnqqquy9utf//qsHc9LjNOY97sp/3XMjxxzRX7qU59KKX05f36syTC0m2++eRx3sV/4tm/7tqz9VV/1VVm76fzHuIs5s+M1jmPs7/7u72btmIM7Xq+mOI1xFuOo1Ad3rfPUlBM2KtVP2Ssn+kjc5za54OPfxHM/qnvQpjZWny699NJx/utSvY9Yl6bpesf7601velPWjscXz0usU/KKV7wia8d54wtf+MKpfXjZy16WteP4U8rF2qaGwaSmGF20PyzVNWlTm6U0r5t8vWvtgUXddttt42v9ghe8IHutqVbNpKbrE8eCWIvklltuydqxLlOsxxP7iDjvahrnS/1I1zzD0Tx9XWmfStso1WVrUsqxPTqOPuYMXX36058eP79eccUV2WtxP+fJf106X13Hu7gPr3nNa6b2obRPpesRazG89rWvzdqx329Ta6M0vyyNLbE/uvnmm7P2f//3f0/tQxx79orV2rUSH3jggXHtpNKc6lWvelXWbnqOjf1jKYd9vBZN9cgmxXPfNM7feeedWfvJT37yzG3Gz+xaX6cp5uK9VnqOivdvPG+l7X3hC1+Y2oc4n4mx9cd//MdT76nlwgsvHJ/3WDshnov4vVBTPYx4rD/yIz+SteMY+f3f//1Ze9Yzfkrt5tGl7/FK41n8Tu4nf/Ins3a8t5r2oRRnJXGbpRovTX3AL/3SL2XteP+N7tk2c4S+HTx4cBwrpXPVph5Had4UxWOO5y/GwHOf+9ys/eY3v3lqm3H+WPrep+v3J/PUAonHGfvp0tyvVAevTVzHzxjNb9o+Q/nFBAAAAAAAUI2FCQAAAAAAoJq5UzmNfjYz+bOPmFrlsccey9rx52xNP2MZ/bRxJP58ML5+8uTJrB33If4sJf5MrEYqp9JPBeN5Smn6OEo/Uyr9FGqen+OU0v+Mzu1oX4f+CfZo+5PnL56n+PO3VUjlFPep6e+bYmBSPI543DGuu6adaNqvrqmc4nHGezPeyzH1U9N74k9JJ49z9Le14m7ynK9DKqc2P3teh1ROJaWfIpb6xpSm9zPG9ih2a/V1k58xGXfxvj916lTWbjNuxL4hHmu8xvE+jfdo6SfG65LKKR53Kb1J6d4opQxo8zejzxjNnZbR15XSA5V+OpzS9HHGuWDp58Vxm3EeGMe/+HpK03Fbmo9K5VR/bjcZd03zg1napHKKfVPX54kYp/H8r2sqp67bGCKV0+jcLXuMjceyiqmcSilrm3RN5RT3YVY/0bRPTf+ta9yV7rd4DE3pXeMzRCmVU62+brLvKc0lSv1USuVUJaXUTqVUTm3SAcf9jNejdC/1kcqp63NUaTwsbb8p5uI2mq5Xabt9a9PXlZ7v2vQz8ZkkzrNK87BSKqemsam036V+J4px3Oa7y9qpnJq2X9rvUVwue4wt3YNt+q74NzE2S2NJ1++v4uspTZ/fONaUjnOI708WHWNLc5U2cb3XWNM27vbtzhmZn//856fytbLd7rnnnnTjjTcOtn0xRxNxR21Dx1xK4o5p+jqWQdxRmzGWZdDXsQzijtqMsSxDKe7mXpjY2dlJx44dS4cOHVpKIRVWx+7ubjpx4kQ6cuRI51XiLsQck8QdtdWKuZTEHV+hr2MZxB21GWNZBn0dyyDuqM0YyzK0jbu5FyYAAAAAAAC6UvwaAAAAAACoxsIEAAAAAABQjYUJAAAAAACgGgsTAAAAAABANRYmAAAAAACAaixMAAAAAAAA1ViYAAAAAAAAqrEwAQAAAAAAVGNhAgAAAAAAqMbCBAAAAAAAUI2FCQAAAAAAoBoLEwAAAAAAQDX/D1XTmOnBi5zmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the original and reconstructed pseudo-gray plots of the strength of H\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "  # display original\n",
    "  ax = plt.subplot(2, n, i + 1 )\n",
    "  x_testplo = abs(x_test[i, 0, :, :]-0.5 + 1j*(x_test[i, 1, :, :]-0.5))\n",
    "  plt.imshow(np.max(np.max(x_testplo))-x_testplo.T)\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "  ax.invert_yaxis()\n",
    "  \n",
    "  # display reconstructed\n",
    "  ax = plt.subplot(2, n, i + 1 + n)\n",
    "  decoded_imgsplo = abs(x_hat[i, 0, :, :]-0.5\n",
    "                        + 1j*(x_hat[i, 1, :, :]-0.5))\n",
    "  plt.imshow(np.max(np.max(decoded_imgsplo))-decoded_imgsplo.T)\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "  ax.invert_yaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TmfCljB0_9oE"
   },
   "outputs": [],
   "source": [
    "# Save the model and the weights of the autoencoder\n",
    "model_json = autoencoder.to_json()\n",
    "outfile = \"files_06_channel/result/model_%s.json\"%file\n",
    "with open(outfile, \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "outfile = \"files_06_channel/result/model_%s.h5\"%file\n",
    "autoencoder.save_weights(outfile)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
